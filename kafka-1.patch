diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/apache-storm-0.9.7/conf/storm.yaml streaming-benchmarks/apache-storm-0.9.7/conf/storm.yaml
*** streaming-benchmarks_git_compact/apache-storm-0.9.7/conf/storm.yaml	2016-08-15 19:07:29.000000000 +0000
--- streaming-benchmarks/apache-storm-0.9.7/conf/storm.yaml	2017-03-07 08:00:29.273000000 +0000
***************
*** 15,25 ****
  # limitations under the License.
  
  ########### These MUST be filled in for a storm configuration
! # storm.zookeeper.servers:
! #     - "server1"
! #     - "server2"
! # 
! # nimbus.host: "nimbus"
  # 
  # 
  # ##### These may optionally be filled in:
--- 15,41 ----
  # limitations under the License.
  
  ########### These MUST be filled in for a storm configuration
! storm.zookeeper.servers:
!     - "10.140.0.101"
!     - "10.140.0.102"
!     - "10.140.0.103"
! 
! nimbus.host: "10.140.0.110"
! nimbus.seeds: "10.140.0.110"
! 
! supervisor.slots.ports:
!     - 6700
!     - 6701
!     - 6702
!     - 6703
! #   - 6704
! #   - 6705
! #   - 6706
! #   - 6707
! #   - 6708
! #   - 6709
! #   - 6710
! storm.local.dir: "storm-local/streaming-group-0-0005"
  # 
  # 
  # ##### These may optionally be filled in:
Only in streaming-benchmarks/apache-storm-0.9.7/examples/storm-starter: storm-starter-topologies-0.9.7.jar
Only in streaming-benchmarks/apache-storm-0.9.7/external/storm-hbase: storm-hbase-0.9.7.jar
Only in streaming-benchmarks/apache-storm-0.9.7/external/storm-hdfs: storm-hdfs-0.9.7.jar
Only in streaming-benchmarks/apache-storm-0.9.7/external/storm-kafka: storm-kafka-0.9.7.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: asm-4.0.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: carbonite-1.4.0.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: chill-java-0.3.5.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: clj-stacktrace-0.2.2.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: clj-time-0.4.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: clojure-1.5.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: clout-1.0.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: commons-codec-1.6.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: commons-exec-1.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: commons-fileupload-1.2.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: commons-io-2.4.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: commons-lang-2.5.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: commons-logging-1.1.3.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: compojure-1.1.3.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: core.incubator-0.1.0.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: disruptor-2.10.4.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: hiccup-0.3.6.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: jetty-6.1.26.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: jetty-util-6.1.26.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: jgrapht-core-0.9.0.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: jline-2.11.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: joda-time-2.0.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: json-simple-1.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: kieker-1.12-emf.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: kryo-2.21.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: libsigar-amd64-linux.so
Only in streaming-benchmarks/apache-storm-0.9.7/lib: log4j-over-slf4j-1.6.6.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: logback-classic-1.0.13.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: logback-core-1.0.13.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: math.numeric-tower-0.0.1.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: minlog-1.2.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: objenesis-1.2.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: reflectasm-1.07-shaded.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: ring-core-1.1.5.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: ring-devel-0.3.11.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: ring-jetty-adapter-0.3.11.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: ring-servlet-0.3.11.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: servlet-api-2.5.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: sigar-1.6.4.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: slf4j-api-1.7.5.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: snakeyaml-1.11.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: storm-core-0.9.7.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: tools.cli-0.2.4.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: tools.logging-0.2.3.jar
Only in streaming-benchmarks/apache-storm-0.9.7/lib: tools.macro-0.1.0.jar
Only in streaming-benchmarks/apache-storm-0.9.7: logs
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/conf/benchmarkConf.yaml streaming-benchmarks/conf/benchmarkConf.yaml
*** streaming-benchmarks_git_compact/conf/benchmarkConf.yaml	2017-06-07 09:17:13.000000000 +0000
--- streaming-benchmarks/conf/benchmarkConf.yaml	2017-03-28 02:40:19.011334827 +0000
***************
*** 2,24 ****
  # Licensed under the terms of the Apache License 2.0. Please see LICENSE file in the project root for terms.
  
  kafka.brokers:
!     - "localhost"
  
  zookeeper.servers:
!     - "localhost"
  
  kafka.port: 9092
  zookeeper.port: 2181
! redis.host: "localhost"
  kafka.topic: "ad-events"
! kafka.partitions: 1
  
  process.hosts: 1
! process.cores: 4
  
  #STORM Specific
! storm.workers: 1
  storm.ackers: 2
  
  #Spark Specific
  spark.batchtime: 2000
--- 2,34 ----
  # Licensed under the terms of the Apache License 2.0. Please see LICENSE file in the project root for terms.
  
  kafka.brokers:
!     - "10.140.0.105"
!     - "10.140.0.106"
!     - "10.140.0.107"
!     - "10.140.0.108"
!     - "10.140.0.109"
  
  zookeeper.servers:
!     - "10.140.0.101"
!     - "10.140.0.102"
!     - "10.140.0.103"
  
  kafka.port: 9092
  zookeeper.port: 2181
! redis.host: "10.140.0.104"
  kafka.topic: "ad-events"
! kafka.partitions: 5
  
  process.hosts: 1
! process.cores: 16
  
  #STORM Specific
! storm.workers: 10
  storm.ackers: 2
  
+ storm.nimbus: "10.140.0.110" # not working?
+ 
  #Spark Specific
  spark.batchtime: 2000
+ 
+ flink.checkpoint-interval: 1000
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/conf/localConf.yaml streaming-benchmarks/conf/localConf.yaml
*** streaming-benchmarks_git_compact/conf/localConf.yaml	2017-06-07 09:31:17.000000000 +0000
--- streaming-benchmarks/conf/localConf.yaml	2017-02-09 14:04:59.291179905 +0000
***************
*** 10,16 ****
  kafka.topic: "ad-events"
  kafka.partitions: 1
  process.hosts: 1
! process.cores: 4
  storm.workers: 1
  storm.ackers: 2
  spark.batchtime: 2000
--- 10,16 ----
  kafka.topic: "ad-events"
  kafka.partitions: 1
  process.hosts: 1
! process.cores: 24
  storm.workers: 1
  storm.ackers: 2
  spark.batchtime: 2000
Only in streaming-benchmarks/conf: localConf.yamle
Only in streaming-benchmarks_git_compact/data: project.clj
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/data/src/setup/core.clj streaming-benchmarks/data/src/setup/core.clj
*** streaming-benchmarks_git_compact/data/src/setup/core.clj	2017-06-07 09:17:13.000000000 +0000
--- streaming-benchmarks/data/src/setup/core.clj	2017-02-08 09:38:50.617000000 +0000
***************
*** 196,204 ****
                t (long (/ t 1000000))]
            (if (> t cur)
              (Thread/sleep (- t cur))
!             (future
!               (if (> cur (+ t 100))
!                 (println "Falling behind by:" (- cur t) "ms"))))
            (send p (record "ad-events"
                            (.getBytes (make-kafka-event-at t with-skew? ads user-ids page-ids)))))))))
  
--- 196,205 ----
                t (long (/ t 1000000))]
            (if (> t cur)
              (Thread/sleep (- t cur))
!           ;;(future
!           ;;  (if (> cur (+ t 100))
!           ;;    (println "Falling behind by:" (- cur t) "ms")))
!             )
            (send p (record "ad-events"
                            (.getBytes (make-kafka-event-at t with-skew? ads user-ids page-ids)))))))))
  
Only in streaming-benchmarks/data: target
Only in streaming-benchmarks: download-cache
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/flink-1.1.3/conf/flink-conf.yaml streaming-benchmarks/flink-1.1.3/conf/flink-conf.yaml
*** streaming-benchmarks_git_compact/flink-1.1.3/conf/flink-conf.yaml	2016-10-10 14:24:55.000000000 +0000
--- streaming-benchmarks/flink-1.1.3/conf/flink-conf.yaml	2017-03-09 07:56:57.719037644 +0000
***************
*** 25,31 ****
  # The JobManager process will use this hostname to bind the listening servers to.
  # The TaskManagers will try to connect to the JobManager on that host.
  
! jobmanager.rpc.address: localhost
  
  
  # The port where the JobManager's main actor system listens for messages.
--- 25,31 ----
  # The JobManager process will use this hostname to bind the listening servers to.
  # The TaskManagers will try to connect to the JobManager on that host.
  
! jobmanager.rpc.address: 10.140.0.110
  
  
  # The port where the JobManager's main actor system listens for messages.
***************
*** 35,51 ****
  
  # The heap size for the JobManager JVM
  
! jobmanager.heap.mb: 256
  
  
  # The heap size for the TaskManager JVM
  
! taskmanager.heap.mb: 512
! 
  
  # The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.
  
! taskmanager.numberOfTaskSlots: 1
  
  # Specify whether TaskManager memory should be allocated when starting up (true) or when
  # memory is required in the memory manager (false)
--- 35,54 ----
  
  # The heap size for the JobManager JVM
  
! #jobmanager.heap.mb: 256
! jobmanager.heap.mb: 1024
  
  
  # The heap size for the TaskManager JVM
  
! #taskmanager.heap.mb: 512
! #taskmanager.heap.mb: 2048
! taskmanager.heap.mb: 15360
  
  # The number of task slots that each TaskManager offers. Each slot runs one parallel pipeline.
  
! #taskmanager.numberOfTaskSlots: 64
! taskmanager.numberOfTaskSlots: 16
  
  # Specify whether TaskManager memory should be allocated when starting up (true) or when
  # memory is required in the memory manager (false)
***************
*** 68,74 ****
  
  # Flag to specify whether job submission is enabled from the web-based
  # runtime monitor. Uncomment to disable.
! 
  #jobmanager.web.submit.enable: false
  
  
--- 71,77 ----
  
  # Flag to specify whether job submission is enabled from the web-based
  # runtime monitor. Uncomment to disable.
! #
  #jobmanager.web.submit.enable: false
  
  
***************
*** 98,104 ****
  
  # The number of buffers for the network stack.
  #
! # taskmanager.network.numberOfBuffers: 2048
  
  
  # Directories for temporary files.
--- 101,111 ----
  
  # The number of buffers for the network stack.
  #
! #taskmanager.network.numberOfBuffers: 2048 # 1~33
! #taskmanager.network.numberOfBuffers: 4096 # ~44
! #taskmanager.network.numberOfBuffers: 6144 # ~54
! #taskmanager.network.numberOfBuffers: 6288 # ~55
! taskmanager.network.numberOfBuffers: 6432
  
  
  # Directories for temporary files.
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/flink-1.1.3/conf/masters streaming-benchmarks/flink-1.1.3/conf/masters
*** streaming-benchmarks_git_compact/flink-1.1.3/conf/masters	2016-10-10 14:24:55.000000000 +0000
--- streaming-benchmarks/flink-1.1.3/conf/masters	2017-03-09 06:29:17.483000000 +0000
***************
*** 1 ****
! localhost:8081
--- 1 ----
! 10.140.0.110:8081
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/flink-1.1.3/conf/slaves streaming-benchmarks/flink-1.1.3/conf/slaves
*** streaming-benchmarks_git_compact/flink-1.1.3/conf/slaves	2016-10-10 14:24:55.000000000 +0000
--- streaming-benchmarks/flink-1.1.3/conf/slaves	2017-03-09 06:29:17.616000000 +0000
***************
*** 1 ****
! localhost
--- 1,10 ----
! 10.140.0.111
! 10.140.0.112
! 10.140.0.113
! 10.140.0.114
! 10.140.0.115
! 10.140.0.116
! 10.140.0.117
! 10.140.0.118
! 10.140.0.119
! 10.140.0.120
Only in streaming-benchmarks/flink-1.1.3/examples/batch: ConnectedComponents.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: DistCp.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: EnumTriangles.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: KMeans.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: PageRank.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: TransitiveClosure.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: WebLogAnalysis.jar
Only in streaming-benchmarks/flink-1.1.3/examples/batch: WordCount.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: IncrementalLearning.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: Iteration.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: Kafka.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: SessionWindowing.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: SocketWindowWordCount.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: TopSpeedWindowing.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: Twitter.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: WindowJoin.jar
Only in streaming-benchmarks/flink-1.1.3/examples/streaming: WordCount.jar
Only in streaming-benchmarks/flink-1.1.3/lib: flink-dist_2.10-1.1.3.jar
Only in streaming-benchmarks/flink-1.1.3/lib: flink-python_2.10-1.1.3.jar
Only in streaming-benchmarks/flink-1.1.3/lib: log4j-1.2.17.jar
Only in streaming-benchmarks/flink-1.1.3/lib: slf4j-log4j12-1.7.7.jar
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/flink-benchmarks/src/main/java/flink/benchmark/AdvertisingTopologyNative.java streaming-benchmarks/flink-benchmarks/src/main/java/flink/benchmark/AdvertisingTopologyNative.java
*** streaming-benchmarks_git_compact/flink-benchmarks/src/main/java/flink/benchmark/AdvertisingTopologyNative.java	2017-06-07 09:17:13.000000000 +0000
--- streaming-benchmarks/flink-benchmarks/src/main/java/flink/benchmark/AdvertisingTopologyNative.java	2017-04-24 02:43:50.911378651 +0000
***************
*** 16,21 ****
--- 16,22 ----
  import org.apache.flink.streaming.api.CheckpointingMode;
  import org.apache.flink.streaming.api.datastream.DataStream;
  import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
+ import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer08;
  import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer082;
  import org.apache.flink.streaming.util.serialization.SimpleStringSchema;
  import org.apache.flink.util.Collector;
***************
*** 25,30 ****
--- 26,45 ----
  
  import java.util.*;
  
+ import java.nio.charset.Charset;
+ import java.nio.file.Files;
+ import java.nio.file.Path;
+ import java.nio.file.Paths;
+ import java.nio.file.StandardOpenOption;
+ import java.io.IOException;
+ import java.net.InetAddress;
+ import java.util.ArrayList;
+ import java.util.Arrays;
+ 
+ import org.apache.flink.streaming.util.serialization.DeserializationSchema;
+ import java.util.Properties;
+ import org.apache.flink.streaming.api.graph.StreamGraph;
+ 
  /**
   * To Run:  flink run target/flink-benchmarks-0.1.0-AdvertisingTopologyNative.jar  --confPath "../conf/benchmarkConf.yaml"
   */
***************
*** 62,68 ****
          env.setParallelism(hosts * cores);
  
          DataStream<String> messageStream = env
!                 .addSource(new FlinkKafkaConsumer082<String>(
                          flinkBenchmarkParams.getRequired("topic"),
                          new SimpleStringSchema(),
                          flinkBenchmarkParams.getProperties())).setParallelism(Math.min(hosts * cores, kafkaPartitions));
--- 76,82 ----
          env.setParallelism(hosts * cores);
  
          DataStream<String> messageStream = env
!                 .addSource(new MyFlinkKafkaConsumer082<String>(
                          flinkBenchmarkParams.getRequired("topic"),
                          new SimpleStringSchema(),
                          flinkBenchmarkParams.getProperties())).setParallelism(Math.min(hosts * cores, kafkaPartitions));
***************
*** 89,96 ****
          env.execute();
      }
  
!     public static class DeserializeBolt implements
!             FlatMapFunction<String, Tuple7<String, String, String, String, String, String, String>> {
  
          @Override
          public void flatMap(String input, Collector<Tuple7<String, String, String, String, String, String, String>> out)
--- 103,208 ----
          env.execute();
      }
  
!     public static class X11ColorScheme {
!         public static List<String> COLORS = Arrays.asList(
!             // 0-9
!             "#FFB6C1", "#FFC0CB", "#DC143C", "#FFF0F5", "#DB7093", "#FF69B4", "#FF1493", "#C71585",
!             "#DA70D6", "#D8BFD8",
! 
!             // 10-21
!             "#a6cee3", "#1f78b4", "#b2df8a", "#33a02c", "#fb9a99", "#e31a1c", "#fdbf6f", "#ff7f00",
!             "#cab2d6", "#6a3d9a", "#ffff99", "#b15928",
! 
!             "#DDA0DD", "#EE82EE", "#FF00FF", "#FF00FF", "#8B008B", "#800080", "#BA55D3", "#9400D3",
!             "#9932CC", "#4B0082", "#8A2BE2", "#9370DB", "#7B68EE", "#6A5ACD", 
! 
!             "#483D8B", "#F8F8FF", "#E6E6FA", "#0000FF", "#0000CD", "#00008B", "#000080", "#191970", 
!             "#4169E1", "#6495ED", "#B0C4DE", "#778899", "#708090", "#1E90FF", "#F0F8FF", "#4682B4", 
!             "#87CEFA", "#87CEEB", "#00BFFF", "#ADD8E6", "#B0E0E6", "#5F9EA0", "#00CED1", "#F0FFFF", 
!             "#E0FFFF", "#AFEEEE", "#00FFFF", "#00FFFF", "#008B8B", "#008080", "#2F4F4F", "#48D1CC",
!             "#20B2AA", "#40E0D0", "#7FFFD4", "#66CDAA", "#00FA9A", "#F5FFFA", "#00FF7F", "#3CB371",
!             "#2E8B57", "#F0FFF0", "#8FBC8F", "#98FB98", "#90EE90", "#32CD32", "#00FF00", "#228B22",
!             "#008000", "#006400", "#7CFC00", "#7FFF00", "#ADFF2F", "#556B2F", "#9ACD32", "#6B8E23",
!             "#FFFFF0", "#F5F5DC", "#FFFFE0", "#FAFAD2", "#FFFF00", "#808000", "#BDB76B", "#EEE8AA", 
!             "#FFFACD", "#F0E68C", "#FFD700", "#FFF8DC", "#DAA520", "#B8860B", "#FFFAF0", "#FDF5E6", 
!             "#F5DEB3", "#FFA500", "#FFE4B5", "#FFEFD5", "#FFEBCD", "#FFDEAD", "#FAEBD7", "#D2B48C", 
!             "#DEB887", "#FF8C00", "#FFE4C4", "#FAF0E6", "#CD853F", "#FFDAB9", "#F4A460", "#D2691E", 
!             "#8B4513", "#FFF5EE", "#A0522D", "#FFA07A", "#FF7F50", "#FF4500", "#E9967A", "#FF6347", 
!             "#FA8072", "#FFE4E1", "#F08080", "#FFFAFA", "#BC8F8F", "#CD5C5C", "#FF0000", "#A52A2A", 
!             "#B22222", "#8B0000", "#800000", "#FFFFFF", "#F5F5F5", "#DCDCDC", "#D3D3D3", "#C0C0C0", 
!             "#A9A9A9", "#808080", "#696969", "#000000");
! 
!         public static String colorAt(int index) {
!             return X11ColorScheme.COLORS.get(index);
!         }
!     }
! 
!     public static class MyFlinkKafkaConsumer082<T> extends FlinkKafkaConsumer08<T> {
! 
!         private static final long serialVersionUID = -5649906773771949146L;
! 
!         public MyFlinkKafkaConsumer082(String topic, DeserializationSchema<T> valueDeserializer, Properties props) {
!             super(topic, valueDeserializer, props);
!         }
! 
!         @Override
!         public void open(Configuration parameters) {
!             RuntimeContext runCtx = getRuntimeContext();
!             try {
!                 String className = this.getClass().getSimpleName();
!                 String host = InetAddress.getLocalHost().getHostName();
!                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
!                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
!                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
!                 String curNode = host + "_" + Integer.toString(this.hashCode());
!                 List<String> lines = new ArrayList<String>();
!                 /*
!                 String srcNode = "???_stream";
!                 lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
!                 lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
!                 */
!                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
!                 ///
!                 String tarNode = "MyFlinkKafkaConsumer082_stream";
!                 lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
!                 lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
!                 ///
!                 Path file = Paths.get("flink_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
!                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
!             } catch (IOException e) { e.printStackTrace(); }
! 
!         }
!     }
! 
!     public static class DeserializeBolt extends
!             RichFlatMapFunction<String, Tuple7<String, String, String, String, String, String, String>> {
! 
!         @Override
!         public void open(Configuration parameters) {
!             RuntimeContext runCtx = getRuntimeContext();
!             try {
!                 String className = this.getClass().getSimpleName();
!                 String host = InetAddress.getLocalHost().getHostName();
!                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
!                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
!                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
!                 String curNode = host + "_" + Integer.toString(this.hashCode());
!                 List<String> lines = new ArrayList<String>();
!                 ///
!                 String srcNode = "MyFlinkKafkaConsumer082_stream";
!                 lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
!                 lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
!                 ///
!                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
!                 ///
!                 String tarNode = "DeserializeBolt_stream";
!                 lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
!                 lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
!                 ///
!                 Path file = Paths.get("flink_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
!                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
!             } catch (IOException e) { e.printStackTrace(); }
!         }
  
          @Override
          public void flatMap(String input, Collector<Tuple7<String, String, String, String, String, String, String>> out)
***************
*** 109,116 ****
          }
      }
  
!     public static class EventFilterBolt implements
!             FilterFunction<Tuple7<String, String, String, String, String, String, String>> {
          @Override
          public boolean filter(Tuple7<String, String, String, String, String, String, String> tuple) throws Exception {
              return tuple.getField(4).equals("view");
--- 221,257 ----
          }
      }
  
!     public static class EventFilterBolt extends
!             RichFilterFunction<Tuple7<String, String, String, String, String, String, String>> {
! 
!         @Override
!         public void open(Configuration parameters) {
!             RuntimeContext runCtx = getRuntimeContext();
!             try {
!                 String className = this.getClass().getSimpleName();
!                 String host = InetAddress.getLocalHost().getHostName();
!                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
!                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
!                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
!                 String curNode = host + "_" + Integer.toString(this.hashCode());
!                 List<String> lines = new ArrayList<String>();
!                 ///
!                 String srcNode = "DeserializeBolt_stream";
!                 lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
!                 lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
!                 ///
!                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
!                 ///
!                 String tarNode = "EventFilterBolt_stream";
!                 lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
!                 lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
!                 ///
!                 Path file = Paths.get("flink_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
!                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
!             } catch (IOException e) { e.printStackTrace(); }
! 
!         }
! 
          @Override
          public boolean filter(Tuple7<String, String, String, String, String, String, String> tuple) throws Exception {
              return tuple.getField(4).equals("view");
***************
*** 129,134 ****
--- 270,300 ----
              LOG.info("Opening connection with Jedis to {}", parameterTool.getRequired("jedis_server"));
              this.redisAdCampaignCache = new RedisAdCampaignCache(parameterTool.getRequired("jedis_server"));
              this.redisAdCampaignCache.prepare();
+ 
+             RuntimeContext runCtx = getRuntimeContext();
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 ///
+                 String srcNode = "EventFilterBolt_stream";
+                 lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                 lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 ///
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 ///
+                 String tarNode = "RedisJoinBolt_stream";
+                 lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                 lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 ///
+                 Path file = Paths.get("flink_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
+ 
          }
  
          @Override
***************
*** 160,165 ****
--- 326,356 ----
  
              this.campaignProcessorCommon = new CampaignProcessorCommon(parameterTool.getRequired("jedis_server"));
              this.campaignProcessorCommon.prepare();
+ 
+             RuntimeContext runCtx = getRuntimeContext();
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 ///
+                 String srcNode = "RedisJoinBolt_stream";
+                 lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                 lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 ///
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 /*
+                 String tarNode = "???_stream";
+                 lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                 lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 */
+                 Path file = Paths.get("flink_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
+ 
          }
  
          @Override
Binary files streaming-benchmarks_git_compact/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$CampaignProcessor.class and streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$CampaignProcessor.class differ
Binary files streaming-benchmarks_git_compact/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative.class and streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative.class differ
Binary files streaming-benchmarks_git_compact/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$DeserializeBolt.class and streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$DeserializeBolt.class differ
Binary files streaming-benchmarks_git_compact/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$EventFilterBolt.class and streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$EventFilterBolt.class differ
Only in streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark: AdvertisingTopologyNative$MyFlinkKafkaConsumer082.class
Binary files streaming-benchmarks_git_compact/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$RedisJoinBolt.class and streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark/AdvertisingTopologyNative$RedisJoinBolt.class differ
Only in streaming-benchmarks/flink-benchmarks/target/classes/flink/benchmark: AdvertisingTopologyNative$X11ColorScheme.class
Only in streaming-benchmarks/flink-benchmarks/target: flink-benchmarks-0.1.0.jar
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/flink-benchmarks/target/maven-archiver/pom.properties streaming-benchmarks/flink-benchmarks/target/maven-archiver/pom.properties
*** streaming-benchmarks_git_compact/flink-benchmarks/target/maven-archiver/pom.properties	2017-06-07 09:31:22.000000000 +0000
--- streaming-benchmarks/flink-benchmarks/target/maven-archiver/pom.properties	2017-04-24 02:46:31.175599033 +0000
***************
*** 1,5 ****
  #Generated by Maven
! #Wed Jun 07 18:31:22 KST 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=flink-benchmarks
--- 1,5 ----
  #Generated by Maven
! #Mon Apr 24 02:46:31 UTC 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=flink-benchmarks
Only in streaming-benchmarks/flink-benchmarks/target: original-flink-benchmarks-0.1.0.jar
Only in streaming-benchmarks_git_compact: .git
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/consumer.properties streaming-benchmarks/kafka_2.10-0.8.2.1/config/consumer.properties
*** streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/consumer.properties	2015-02-26 22:02:45.000000000 +0000
--- streaming-benchmarks/kafka_2.10-0.8.2.1/config/consumer.properties	2017-02-27 12:19:00.765075971 +0000
***************
*** 17,23 ****
  # Zookeeper connection string
  # comma separated host:port pairs, each corresponding to a zk
  # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"
! zookeeper.connect=127.0.0.1:2181
  
  # timeout in ms for connecting to zookeeper
  zookeeper.connection.timeout.ms=6000
--- 17,23 ----
  # Zookeeper connection string
  # comma separated host:port pairs, each corresponding to a zk
  # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"
! zookeeper.connect=10.140.0.101:2181,10.140.0.102:2181,10.140.0.103:2181
  
  # timeout in ms for connecting to zookeeper
  zookeeper.connection.timeout.ms=6000
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/producer.properties streaming-benchmarks/kafka_2.10-0.8.2.1/config/producer.properties
*** streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/producer.properties	2015-02-26 22:02:45.000000000 +0000
--- streaming-benchmarks/kafka_2.10-0.8.2.1/config/producer.properties	2017-02-27 12:21:05.489280839 +0000
***************
*** 18,24 ****
  
  # list of brokers used for bootstrapping knowledge about the rest of the cluster
  # format: host1:port1,host2:port2 ...
! metadata.broker.list=localhost:9092
  
  # name of the partitioner class for partitioning events; default partition spreads data randomly
  #partitioner.class=
--- 18,24 ----
  
  # list of brokers used for bootstrapping knowledge about the rest of the cluster
  # format: host1:port1,host2:port2 ...
! metadata.broker.list=10.140.0.105:9092,10.140.0.106:9092,10.140.0.107:9092,10.140.0.108:9092,10.140.0.109:9092 
  
  # name of the partitioner class for partitioning events; default partition spreads data randomly
  #partitioner.class=
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/server.properties streaming-benchmarks/kafka_2.10-0.8.2.1/config/server.properties
*** streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/server.properties	2015-02-26 22:02:45.000000000 +0000
--- streaming-benchmarks/kafka_2.10-0.8.2.1/config/server.properties	2017-03-03 02:39:47.851166501 +0000
***************
*** 17,23 ****
  ############################# Server Basics #############################
  
  # The id of the broker. This must be set to a unique integer for each broker.
! broker.id=0
  
  ############################# Socket Server Settings #############################
  
--- 17,23 ----
  ############################# Server Basics #############################
  
  # The id of the broker. This must be set to a unique integer for each broker.
! broker.id=1
  
  ############################# Socket Server Settings #############################
  
***************
*** 25,31 ****
  port=9092
  
  # Hostname the broker will bind to. If not set, the server will bind to all interfaces
! #host.name=localhost
  
  # Hostname the broker will advertise to producers and consumers. If not set, it uses the
  # value for "host.name" if configured.  Otherwise, it will use the value returned from
--- 25,31 ----
  port=9092
  
  # Hostname the broker will bind to. If not set, the server will bind to all interfaces
! #host.name=10.140.0.105
  
  # Hostname the broker will advertise to producers and consumers. If not set, it uses the
  # value for "host.name" if configured.  Otherwise, it will use the value returned from
***************
*** 55,66 ****
  ############################# Log Basics #############################
  
  # A comma seperated list of directories under which to store log files
! log.dirs=/tmp/kafka-logs
  
  # The default number of log partitions per topic. More partitions allow greater
  # parallelism for consumption, but this will also result in more files across
  # the brokers.
! num.partitions=1
  
  # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
  # This value is recommended to be increased for installations with data dirs located in RAID array.
--- 55,66 ----
  ############################# Log Basics #############################
  
  # A comma seperated list of directories under which to store log files
! log.dirs=/tmp/kafka-logs-1
  
  # The default number of log partitions per topic. More partitions allow greater
  # parallelism for consumption, but this will also result in more files across
  # the brokers.
! num.partitions=5
  
  # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
  # This value is recommended to be increased for installations with data dirs located in RAID array.
***************
*** 115,121 ****
  # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
  # You can also append an optional chroot string to the urls to specify the
  # root directory for all kafka znodes.
! zookeeper.connect=localhost:2181
  
  # Timeout in ms for connecting to zookeeper
  zookeeper.connection.timeout.ms=6000
--- 115,121 ----
  # server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
  # You can also append an optional chroot string to the urls to specify the
  # root directory for all kafka znodes.
! zookeeper.connect=10.140.0.101:2181,10.140.0.102:2181,10.140.0.103:2181
  
  # Timeout in ms for connecting to zookeeper
  zookeeper.connection.timeout.ms=6000
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/zookeeper.properties streaming-benchmarks/kafka_2.10-0.8.2.1/config/zookeeper.properties
*** streaming-benchmarks_git_compact/kafka_2.10-0.8.2.1/config/zookeeper.properties	2015-02-26 22:02:45.000000000 +0000
--- streaming-benchmarks/kafka_2.10-0.8.2.1/config/zookeeper.properties	2017-03-02 08:28:45.683067821 +0000
***************
*** 18,20 ****
--- 18,26 ----
  clientPort=2181
  # disable the per-ip limit on the number of connections since this is a non-production config
  maxClientCnxns=0
+ tickTime=2000
+ initLimit=5
+ syncLimit=2
+ server.1=10.140.0.101:2888:3888
+ server.2=10.140.0.102:2888:3888
+ server.3=10.140.0.103:2888:3888
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: jopt-simple-3.2.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: kafka_2.10-0.8.2.1.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: kafka_2.10-0.8.2.1-javadoc.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: kafka_2.10-0.8.2.1-scaladoc.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: kafka_2.10-0.8.2.1-sources.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: kafka_2.10-0.8.2.1-test.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: kafka-clients-0.8.2.1.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: log4j-1.2.16.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: lz4-1.2.0.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: metrics-core-2.2.0.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: scala-library-2.10.4.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: slf4j-api-1.7.6.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: slf4j-log4j12-1.6.1.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: snappy-java-1.1.1.6.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: zkclient-0.3.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1/libs: zookeeper-3.4.6.jar
Only in streaming-benchmarks/kafka_2.10-0.8.2.1: logs
Only in streaming-benchmarks: logs
Only in streaming-benchmarks/redis-3.0.5/deps/hiredis: async.o
Only in streaming-benchmarks/redis-3.0.5/deps/hiredis: hiredis.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/deps/hiredis/libhiredis.a and streaming-benchmarks/redis-3.0.5/deps/hiredis/libhiredis.a differ
Only in streaming-benchmarks/redis-3.0.5/deps/hiredis: net.o
Only in streaming-benchmarks/redis-3.0.5/deps/hiredis: sds.o
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/config.log streaming-benchmarks/redis-3.0.5/deps/jemalloc/config.log
*** streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/config.log	2017-06-07 09:31:37.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/deps/jemalloc/config.log	2017-02-22 05:02:59.743116568 +0000
***************
*** 10,25 ****
  ## Platform. ##
  ## --------- ##
  
! hostname = elc-1
  uname -m = x86_64
! uname -r = 4.4.0-47-generic
  uname -s = Linux
! uname -v = #68~14.04.1-Ubuntu SMP Wed Oct 26 19:42:11 UTC 2016
  
! /usr/bin/uname -p = unknown
  /bin/uname -X     = unknown
  
! /bin/arch              = unknown
  /usr/bin/arch -k       = unknown
  /usr/convex/getsysinfo = unknown
  /usr/bin/hostinfo      = unknown
--- 10,25 ----
  ## Platform. ##
  ## --------- ##
  
! hostname = ip-172-31-42-227
  uname -m = x86_64
! uname -r = 3.10.0-327.10.1.el7.x86_64
  uname -s = Linux
! uname -v = #1 SMP Tue Feb 16 17:03:50 UTC 2016
  
! /usr/bin/uname -p = x86_64
  /bin/uname -X     = unknown
  
! /bin/arch              = x86_64
  /usr/bin/arch -k       = unknown
  /usr/convex/getsysinfo = unknown
  /usr/bin/hostinfo      = unknown
***************
*** 27,50 ****
  /usr/bin/oslevel       = unknown
  /bin/universe          = unknown
  
- PATH: /opt/texlive/bin/x86_64-linux
  PATH: /opt/gcc/5.4.0/bin
  PATH: /opt/jvm/jdk1.8.0_74/bin
  PATH: /opt/jvm/jdk1.8.0_74/jre/bin
  PATH: /opt/maven/3.3.9/bin
  PATH: /opt/apache-storm-0.9.5/bin
! PATH: /home/shyang/bin
! PATH: /usr/local/sbin
  PATH: /usr/local/bin
- PATH: /usr/sbin
  PATH: /usr/bin
! PATH: /sbin
! PATH: /bin
! PATH: /usr/games
! PATH: /usr/local/games
  PATH: /opt/Swift/2.2/usr/bin
  PATH: /home/shyang/bin
- PATH: /opt/gcloud/151.0.1/bin
  
  
  ## ----------- ##
--- 27,52 ----
  /usr/bin/oslevel       = unknown
  /bin/universe          = unknown
  
  PATH: /opt/gcc/5.4.0/bin
  PATH: /opt/jvm/jdk1.8.0_74/bin
  PATH: /opt/jvm/jdk1.8.0_74/jre/bin
  PATH: /opt/maven/3.3.9/bin
  PATH: /opt/apache-storm-0.9.5/bin
! PATH: /opt/gcc/5.4.0/bin
! PATH: /opt/jvm/jdk1.8.0_74/bin
! PATH: /opt/jvm/jdk1.8.0_74/jre/bin
! PATH: /opt/maven/3.3.9/bin
! PATH: /opt/apache-storm-0.9.5/bin
  PATH: /usr/local/bin
  PATH: /usr/bin
! PATH: /usr/local/sbin
! PATH: /usr/sbin
! PATH: /opt/Swift/2.2/usr/bin
! PATH: /home/shyang/bin
! PATH: /home/centos/.local/bin
! PATH: /home/centos/bin
  PATH: /opt/Swift/2.2/usr/bin
  PATH: /home/shyang/bin
  
  
  ## ----------- ##
***************
*** 54,64 ****
  configure:2523: checking for xsltproc
  configure:2554: result: false
  configure:2635: checking for gcc
! configure:2651: found /opt/gcc/5.4.0/bin/gcc
  configure:2662: result: gcc
  configure:2891: checking for C compiler version
  configure:2900: gcc --version >&5
! gcc (GCC) 5.4.0
  Copyright (C) 2015 Free Software Foundation, Inc.
  This is free software; see the source for copying conditions.  There is NO
  warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
--- 56,66 ----
  configure:2523: checking for xsltproc
  configure:2554: result: false
  configure:2635: checking for gcc
! configure:2651: found /usr/bin/gcc
  configure:2662: result: gcc
  configure:2891: checking for C compiler version
  configure:2900: gcc --version >&5
! gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
  Copyright (C) 2015 Free Software Foundation, Inc.
  This is free software; see the source for copying conditions.  There is NO
  warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
***************
*** 67,88 ****
  configure:2900: gcc -v >&5
  Using built-in specs.
  COLLECT_GCC=gcc
! COLLECT_LTO_WRAPPER=/opt/gcc/5.4.0/libexec/gcc/x86_64-unknown-linux-gnu/5.4.0/lto-wrapper
! Target: x86_64-unknown-linux-gnu
! Configured with: ../gcc-5.4.0/configure --prefix=/opt/gcc/5.4.0 --disable-multilib --enable-languages=c,c++,lto
  Thread model: posix
! gcc version 5.4.0 (GCC) 
  configure:2911: $? = 0
  configure:2900: gcc -V >&5
  gcc: error: unrecognized command line option '-V'
  gcc: fatal error: no input files
  compilation terminated.
! configure:2911: $? = 1
  configure:2900: gcc -qversion >&5
  gcc: error: unrecognized command line option '-qversion'
  gcc: fatal error: no input files
  compilation terminated.
! configure:2911: $? = 1
  configure:2931: checking whether the C compiler works
  configure:2953: gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops    conftest.c  >&5
  configure:2957: $? = 0
--- 69,90 ----
  configure:2900: gcc -v >&5
  Using built-in specs.
  COLLECT_GCC=gcc
! COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/4.8.5/lto-wrapper
! Target: x86_64-redhat-linux
! Configured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux
  Thread model: posix
! gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) 
  configure:2911: $? = 0
  configure:2900: gcc -V >&5
  gcc: error: unrecognized command line option '-V'
  gcc: fatal error: no input files
  compilation terminated.
! configure:2911: $? = 4
  configure:2900: gcc -qversion >&5
  gcc: error: unrecognized command line option '-qversion'
  gcc: fatal error: no input files
  compilation terminated.
! configure:2911: $? = 4
  configure:2931: checking whether the C compiler works
  configure:2953: gcc -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops    conftest.c  >&5
  configure:2957: $? = 0
***************
*** 120,125 ****
--- 122,129 ----
  configure:3749: $? = 0
  configure:3763: gcc -E  conftest.c
  conftest.c:9:28: fatal error: ac_nonexistent.h: No such file or directory
+  #include <ac_nonexistent.h>
+                             ^
  compilation terminated.
  configure:3763: $? = 1
  configure: failed program was:
***************
*** 137,142 ****
--- 141,148 ----
  configure:3808: $? = 0
  configure:3822: gcc -E  conftest.c
  conftest.c:9:28: fatal error: ac_nonexistent.h: No such file or directory
+  #include <ac_nonexistent.h>
+                             ^
  compilation terminated.
  configure:3822: $? = 1
  configure: failed program was:
***************
*** 150,158 ****
  | /* end confdefs.h.  */
  | #include <ac_nonexistent.h>
  configure:3852: checking for grep that handles long lines and -e
! configure:3910: result: /bin/grep
  configure:3915: checking for egrep
! configure:3977: result: /bin/grep -E
  configure:3982: checking for ANSI C header files
  configure:4002: gcc -c -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops   conftest.c >&5
  configure:4002: $? = 0
--- 156,164 ----
  | /* end confdefs.h.  */
  | #include <ac_nonexistent.h>
  configure:3852: checking for grep that handles long lines and -e
! configure:3910: result: /usr/bin/grep
  configure:3915: checking for egrep
! configure:3977: result: /usr/bin/grep -E
  configure:3982: checking for ANSI C header files
  configure:4002: gcc -c -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops   conftest.c >&5
  configure:4002: $? = 0
***************
*** 388,395 ****
  configure:5343: found /usr/bin/ld
  configure:5356: result: /usr/bin/ld
  configure:5366: checking for autoconf
! configure:5384: found /usr/bin/autoconf
! configure:5397: result: /usr/bin/autoconf
  configure:5408: checking for memalign
  configure:5408: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE  conftest.c  >&5
  configure:5408: $? = 0
--- 394,400 ----
  configure:5343: found /usr/bin/ld
  configure:5356: result: /usr/bin/ld
  configure:5366: checking for autoconf
! configure:5397: result: false
  configure:5408: checking for memalign
  configure:5408: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE  conftest.c  >&5
  configure:5408: $? = 0
***************
*** 407,412 ****
--- 412,419 ----
  configure:6352: checking whether utrace(2) is compilable
  configure:6376: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE  conftest.c  >&5
  conftest.c:51:24: fatal error: sys/ktrace.h: No such file or directory
+  #include <sys/ktrace.h>
+                         ^
  compilation terminated.
  configure:6376: $? = 1
  configure: failed program was:
***************
*** 475,480 ****
--- 482,489 ----
  configure:6411: checking whether valgrind is compilable
  configure:6434: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE  conftest.c  >&5
  conftest.c:47:31: fatal error: valgrind/valgrind.h: No such file or directory
+  #include <valgrind/valgrind.h>
+                                ^
  compilation terminated.
  configure:6434: $? = 1
  configure: failed program was:
***************
*** 542,548 ****
  configure:6474: checking STATIC_PAGE_SHIFT
  configure:6528: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE  conftest.c  >&5
  conftest.c: In function 'main':
! conftest.c:72:14: warning: implicit declaration of function 'ffsl' [-Wimplicit-function-declaration]
       result = ffsl(result) - 1;
                ^
  configure:6528: $? = 0
--- 551,557 ----
  configure:6474: checking STATIC_PAGE_SHIFT
  configure:6528: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE  conftest.c  >&5
  conftest.c: In function 'main':
! conftest.c:72:5: warning: implicit declaration of function 'ffsl' [-Wimplicit-function-declaration]
       result = ffsl(result) - 1;
       ^
  configure:6528: $? = 0
***************
*** 565,572 ****
  configure:6617: result: yes
  configure:6686: checking for _malloc_thread_cleanup
  configure:6686: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
! /tmp/ccHWpWh5.o: In function `main':
! /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/conftest.c:82: undefined reference to `_malloc_thread_cleanup'
  collect2: error: ld returned 1 exit status
  configure:6686: $? = 1
  configure: failed program was:
--- 574,581 ----
  configure:6617: result: yes
  configure:6686: checking for _malloc_thread_cleanup
  configure:6686: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
! /tmp/cc2M7BWP.o: In function `main':
! /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/conftest.c:82: undefined reference to `_malloc_thread_cleanup'
  collect2: error: ld returned 1 exit status
  configure:6686: $? = 1
  configure: failed program was:
***************
*** 658,665 ****
  configure:6686: result: no
  configure:6700: checking for _pthread_mutex_init_calloc_cb
  configure:6700: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
! /tmp/ccZ5geO7.o: In function `main':
! /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/conftest.c:82: undefined reference to `_pthread_mutex_init_calloc_cb'
  collect2: error: ld returned 1 exit status
  configure:6700: $? = 1
  configure: failed program was:
--- 667,674 ----
  configure:6686: result: no
  configure:6700: checking for _pthread_mutex_init_calloc_cb
  configure:6700: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
! /tmp/ccTed8mR.o: In function `main':
! /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/conftest.c:82: undefined reference to `_pthread_mutex_init_calloc_cb'
  collect2: error: ld returned 1 exit status
  configure:6700: $? = 1
  configure: failed program was:
***************
*** 760,765 ****
--- 769,776 ----
  configure:6908: checking whether atomic(9) is compilable
  configure:6939: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
  conftest.c:51:28: fatal error: machine/atomic.h: No such file or directory
+  #include <machine/atomic.h>
+                             ^
  compilation terminated.
  configure:6939: $? = 1
  configure: failed program was:
***************
*** 838,843 ****
--- 849,856 ----
  configure:6957: checking whether Darwin OSAtomic*() is compilable
  configure:6987: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
  conftest.c:50:30: fatal error: libkern/OSAtomic.h: No such file or directory
+  #include <libkern/OSAtomic.h>
+                               ^
  compilation terminated.
  configure:6987: $? = 1
  configure: failed program was:
***************
*** 1069,1074 ****
--- 1082,1089 ----
  configure:7101: checking whether Darwin OSSpin*() is compilable
  configure:7124: gcc -o conftest -std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden  -D_GNU_SOURCE -D_REENTRANT  conftest.c  -lpthread >&5
  conftest.c:50:30: fatal error: libkern/OSAtomic.h: No such file or directory
+  #include <libkern/OSAtomic.h>
+                               ^
  compilation terminated.
  configure:7124: $? = 1
  configure: failed program was:
***************
*** 1289,1295 ****
    CONFIG_COMMANDS = 
    $ ./config.status 
  
! on elc-1
  
  config.status:986: creating Makefile
  config.status:986: creating doc/html.xsl
--- 1304,1310 ----
    CONFIG_COMMANDS = 
    $ ./config.status 
  
! on ip-172-31-42-227
  
  config.status:986: creating Makefile
  config.status:986: creating doc/html.xsl
***************
*** 1303,1310 ****
--- 1318,1328 ----
  config.status:986: creating config.stamp
  config.status:986: creating bin/jemalloc.sh
  config.status:986: creating include/jemalloc/jemalloc_defs.h
+ config.status:1161: include/jemalloc/jemalloc_defs.h is unchanged
  config.status:986: creating include/jemalloc/internal/jemalloc_internal_defs.h
+ config.status:1161: include/jemalloc/internal/jemalloc_internal_defs.h is unchanged
  config.status:986: creating test/include/test/jemalloc_test_defs.h
+ config.status:1161: test/include/test/jemalloc_test_defs.h is unchanged
  config.status:1175: executing include/jemalloc/internal/private_namespace.h commands
  config.status:1175: executing include/jemalloc/internal/private_unnamespace.h commands
  config.status:1175: executing include/jemalloc/internal/public_symbols.txt commands
***************
*** 1329,1335 ****
  configure:8879: result: RPATH_EXTRA        : 
  configure:8881: result: 
  configure:8883: result: XSLTPROC           : false
! configure:8885: result: XSLROOT            : /usr/share/xml/docbook/stylesheet/docbook-xsl
  configure:8887: result: 
  configure:8889: result: PREFIX             : /usr/local
  configure:8891: result: BINDIR             : /usr/local/bin
--- 1347,1353 ----
  configure:8879: result: RPATH_EXTRA        : 
  configure:8881: result: 
  configure:8883: result: XSLTPROC           : false
! configure:8885: result: XSLROOT            : 
  configure:8887: result: 
  configure:8889: result: PREFIX             : /usr/local
  configure:8891: result: BINDIR             : /usr/local/bin
***************
*** 1339,1347 ****
  configure:8899: result: MANDIR             : /usr/local/share/man
  configure:8901: result: 
  configure:8903: result: srcroot            : 
! configure:8905: result: abs_srcroot        : /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
  configure:8907: result: objroot            : 
! configure:8909: result: abs_objroot        : /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
  configure:8911: result: 
  configure:8913: result: JEMALLOC_PREFIX    : je_
  configure:8915: result: JEMALLOC_PRIVATE_NAMESPACE
--- 1357,1365 ----
  configure:8899: result: MANDIR             : /usr/local/share/man
  configure:8901: result: 
  configure:8903: result: srcroot            : 
! configure:8905: result: abs_srcroot        : /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
  configure:8907: result: objroot            : 
! configure:8909: result: abs_objroot        : /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
  configure:8911: result: 
  configure:8913: result: JEMALLOC_PREFIX    : je_
  configure:8915: result: JEMALLOC_PRIVATE_NAMESPACE
***************
*** 1415,1423 ****
  ac_cv_host=x86_64-unknown-linux-gnu
  ac_cv_lib_pthread_pthread_create=yes
  ac_cv_objext=o
! ac_cv_path_AUTOCONF=/usr/bin/autoconf
! ac_cv_path_EGREP='/bin/grep -E'
! ac_cv_path_GREP=/bin/grep
  ac_cv_path_LD=/usr/bin/ld
  ac_cv_path_XSLTPROC=false
  ac_cv_path_install='/usr/bin/install -c'
--- 1433,1441 ----
  ac_cv_host=x86_64-unknown-linux-gnu
  ac_cv_lib_pthread_pthread_create=yes
  ac_cv_objext=o
! ac_cv_path_AUTOCONF=false
! ac_cv_path_EGREP='/usr/bin/grep -E'
! ac_cv_path_GREP=/usr/bin/grep
  ac_cv_path_LD=/usr/bin/ld
  ac_cv_path_XSLTPROC=false
  ac_cv_path_install='/usr/bin/install -c'
***************
*** 1454,1460 ****
  AR='ar'
  ARFLAGS='crus'
  AROUT=' $@'
! AUTOCONF='/usr/bin/autoconf'
  BINDIR='/usr/local/bin'
  CC='gcc'
  CC_MM='1'
--- 1472,1478 ----
  AR='ar'
  ARFLAGS='crus'
  AROUT=' $@'
! AUTOCONF='false'
  BINDIR='/usr/local/bin'
  CC='gcc'
  CC_MM='1'
***************
*** 1468,1477 ****
  ECHO_C=''
  ECHO_N='-n'
  ECHO_T=''
! EGREP='/bin/grep -E'
  EXEEXT=''
  EXTRA_LDFLAGS=''
! GREP='/bin/grep'
  INCLUDEDIR='/usr/local/include'
  INSTALL_DATA='${INSTALL} -m 644'
  INSTALL_PROGRAM='${INSTALL}'
--- 1486,1495 ----
  ECHO_C=''
  ECHO_N='-n'
  ECHO_T=''
! EGREP='/usr/bin/grep -E'
  EXEEXT=''
  EXTRA_LDFLAGS=''
! GREP='/usr/bin/grep'
  INCLUDEDIR='/usr/local/include'
  INSTALL_DATA='${INSTALL} -m 644'
  INSTALL_PROGRAM='${INSTALL}'
***************
*** 1499,1512 ****
  RANLIB='ranlib'
  RPATH='-Wl,-rpath,$(1)'
  RPATH_EXTRA=''
! SHELL='/bin/bash'
  SOREV='so.1'
! XSLROOT='/usr/share/xml/docbook/stylesheet/docbook-xsl'
  XSLTPROC='false'
  a='a'
  abi='elf'
! abs_objroot='/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/'
! abs_srcroot='/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/'
  ac_ct_CC='gcc'
  bindir='${exec_prefix}/bin'
  build='x86_64-unknown-linux-gnu'
--- 1517,1530 ----
  RANLIB='ranlib'
  RPATH='-Wl,-rpath,$(1)'
  RPATH_EXTRA=''
! SHELL='/bin/sh'
  SOREV='so.1'
! XSLROOT=''
  XSLTPROC='false'
  a='a'
  abi='elf'
! abs_objroot='/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/'
! abs_srcroot='/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/'
  ac_ct_CC='gcc'
  bindir='${exec_prefix}/bin'
  build='x86_64-unknown-linux-gnu'
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/config.status streaming-benchmarks/redis-3.0.5/deps/jemalloc/config.status
*** streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/config.status	2017-06-07 09:31:37.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/deps/jemalloc/config.status	2017-02-22 05:02:59.743116568 +0000
***************
*** 1,4 ****
! #! /bin/bash
  # Generated by configure.
  # Run this file to recreate the current configuration.
  # Compiler output produced by configure, useful for debugging
--- 1,4 ----
! #! /bin/sh
  # Generated by configure.
  # Run this file to recreate the current configuration.
  # Compiler output produced by configure, useful for debugging
***************
*** 8,14 ****
  ac_cs_recheck=false
  ac_cs_silent=false
  
! SHELL=${CONFIG_SHELL-/bin/bash}
  export SHELL
  ## -------------------- ##
  ## M4sh Initialization. ##
--- 8,14 ----
  ac_cs_recheck=false
  ac_cs_silent=false
  
! SHELL=${CONFIG_SHELL-/bin/sh}
  export SHELL
  ## -------------------- ##
  ## M4sh Initialization. ##
***************
*** 437,443 ****
  This config.status script is free software; the Free Software Foundation
  gives unlimited permission to copy, distribute and modify it."
  
! ac_pwd='/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc'
  srcdir='.'
  INSTALL='/usr/bin/install -c'
  test -n "$AWK" || AWK=awk
--- 437,443 ----
  This config.status script is free software; the Free Software Foundation
  gives unlimited permission to copy, distribute and modify it."
  
! ac_pwd='/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc'
  srcdir='.'
  INSTALL='/usr/bin/install -c'
  test -n "$AWK" || AWK=awk
***************
*** 517,526 ****
  fi
  
  if $ac_cs_recheck; then
!   set X /bin/bash './configure'  '--with-jemalloc-prefix=je_' '--enable-cc-silence' 'CFLAGS=-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops ' 'LDFLAGS=' $ac_configure_extra_args --no-create --no-recursion
    shift
!   $as_echo "running CONFIG_SHELL=/bin/bash $*" >&6
!   CONFIG_SHELL='/bin/bash'
    export CONFIG_SHELL
    exec "$@"
  fi
--- 517,526 ----
  fi
  
  if $ac_cs_recheck; then
!   set X /bin/sh './configure'  '--with-jemalloc-prefix=je_' '--enable-cc-silence' 'CFLAGS=-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops ' 'LDFLAGS=' $ac_configure_extra_args --no-create --no-recursion
    shift
!   $as_echo "running CONFIG_SHELL=/bin/sh $*" >&6
!   CONFIG_SHELL='/bin/sh'
    export CONFIG_SHELL
    exec "$@"
  fi
***************
*** 710,716 ****
  S["private_namespace"]="je_"
  S["enable_code_coverage"]="0"
  S["enable_experimental"]="1"
! S["AUTOCONF"]="/usr/bin/autoconf"
  S["LD"]="/usr/bin/ld"
  S["RANLIB"]="ranlib"
  S["INSTALL_DATA"]="${INSTALL} -m 644"
--- 710,716 ----
  S["private_namespace"]="je_"
  S["enable_code_coverage"]="0"
  S["enable_experimental"]="1"
! S["AUTOCONF"]="false"
  S["LD"]="/usr/bin/ld"
  S["RANLIB"]="ranlib"
  S["INSTALL_DATA"]="${INSTALL} -m 644"
***************
*** 746,753 ****
  S["build_vendor"]="unknown"
  S["build_cpu"]="x86_64"
  S["build"]="x86_64-unknown-linux-gnu"
! S["EGREP"]="/bin/grep -E"
! S["GREP"]="/bin/grep"
  S["CPP"]="gcc -E"
  S["OBJEXT"]="o"
  S["EXEEXT"]=""
--- 746,753 ----
  S["build_vendor"]="unknown"
  S["build_cpu"]="x86_64"
  S["build"]="x86_64-unknown-linux-gnu"
! S["EGREP"]="/usr/bin/grep -E"
! S["GREP"]="/usr/bin/grep"
  S["CPP"]="gcc -E"
  S["OBJEXT"]="o"
  S["EXEEXT"]=""
***************
*** 756,762 ****
  S["LDFLAGS"]=""
  S["CFLAGS"]="-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden"
  S["CC"]="gcc"
! S["XSLROOT"]="/usr/share/xml/docbook/stylesheet/docbook-xsl"
  S["XSLTPROC"]="false"
  S["MANDIR"]="/usr/local/share/man"
  S["DATADIR"]="/usr/local/share"
--- 756,762 ----
  S["LDFLAGS"]=""
  S["CFLAGS"]="-std=gnu99 -Wall -pipe -g3 -O3 -funroll-loops  -fvisibility=hidden"
  S["CC"]="gcc"
! S["XSLROOT"]=""
  S["XSLTPROC"]="false"
  S["MANDIR"]="/usr/local/share/man"
  S["DATADIR"]="/usr/local/share"
***************
*** 764,772 ****
  S["INCLUDEDIR"]="/usr/local/include"
  S["BINDIR"]="/usr/local/bin"
  S["PREFIX"]="/usr/local"
! S["abs_objroot"]="/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/"
  S["objroot"]=""
! S["abs_srcroot"]="/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/"
  S["srcroot"]=""
  S["rev"]="1"
  S["target_alias"]=""
--- 764,772 ----
  S["INCLUDEDIR"]="/usr/local/include"
  S["BINDIR"]="/usr/local/bin"
  S["PREFIX"]="/usr/local"
! S["abs_objroot"]="/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/"
  S["objroot"]=""
! S["abs_srcroot"]="/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/"
  S["srcroot"]=""
  S["rev"]="1"
  S["target_alias"]=""
***************
*** 806,812 ****
  S["PACKAGE_TARNAME"]=""
  S["PACKAGE_NAME"]=""
  S["PATH_SEPARATOR"]=":"
! S["SHELL"]="/bin/bash"
  _ACAWK
  cat >>"$ac_tmp/subs1.awk" <<_ACAWK &&
    for (key in S) S_is_set[key] = 1
--- 806,812 ----
  S["PACKAGE_TARNAME"]=""
  S["PACKAGE_NAME"]=""
  S["PATH_SEPARATOR"]=":"
! S["SHELL"]="/bin/sh"
  _ACAWK
  cat >>"$ac_tmp/subs1.awk" <<_ACAWK &&
    for (key in S) S_is_set[key] = 1
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/doc/html.xsl streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/html.xsl
*** streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/doc/html.xsl	2017-06-07 09:31:37.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/html.xsl	2017-02-22 05:02:59.628116474 +0000
***************
*** 1,4 ****
  <xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
!   <xsl:import href="/usr/share/xml/docbook/stylesheet/docbook-xsl/html/docbook.xsl"/>
!   <xsl:import href="/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/stylesheet.xsl"/>
  </xsl:stylesheet>
--- 1,4 ----
  <xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
!   <xsl:import href="/html/docbook.xsl"/>
!   <xsl:import href="/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/stylesheet.xsl"/>
  </xsl:stylesheet>
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/doc/manpages.xsl streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/manpages.xsl
*** streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/doc/manpages.xsl	2017-06-07 09:31:37.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/manpages.xsl	2017-02-22 05:02:59.627116473 +0000
***************
*** 1,4 ****
  <xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
!   <xsl:import href="/usr/share/xml/docbook/stylesheet/docbook-xsl/manpages/docbook.xsl"/>
!   <xsl:import href="/home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/stylesheet.xsl"/>
  </xsl:stylesheet>
--- 1,4 ----
  <xsl:stylesheet xmlns:xsl="http://www.w3.org/1999/XSL/Transform" version="1.0">
!   <xsl:import href="/manpages/docbook.xsl"/>
!   <xsl:import href="/home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/doc/stylesheet.xsl"/>
  </xsl:stylesheet>
Binary files streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/lib/libjemalloc.a and streaming-benchmarks/redis-3.0.5/deps/jemalloc/lib/libjemalloc.a differ
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/Makefile streaming-benchmarks/redis-3.0.5/deps/jemalloc/Makefile
*** streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/Makefile	2017-06-07 09:31:37.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/deps/jemalloc/Makefile	2017-02-22 05:02:59.633116478 +0000
***************
*** 19,26 ****
  MANDIR := $(DESTDIR)/usr/local/share/man
  srcroot := 
  objroot := 
! abs_srcroot := /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
! abs_objroot := /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
  
  # Build parameters.
  CPPFLAGS :=  -D_GNU_SOURCE -D_REENTRANT -I$(srcroot)include -I$(objroot)include
--- 19,26 ----
  MANDIR := $(DESTDIR)/usr/local/share/man
  srcroot := 
  objroot := 
! abs_srcroot := /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
! abs_objroot := /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
  
  # Build parameters.
  CPPFLAGS :=  -D_GNU_SOURCE -D_REENTRANT -I$(srcroot)include -I$(objroot)include
***************
*** 39,45 ****
  install_suffix := 
  ABI := elf
  XSLTPROC := false
! AUTOCONF := /usr/bin/autoconf
  _RPATH = -Wl,-rpath,$(1)
  RPATH = $(if $(1),$(call _RPATH,$(1)))
  cfghdrs_in := include/jemalloc/jemalloc_defs.h.in include/jemalloc/internal/jemalloc_internal_defs.h.in include/jemalloc/internal/private_namespace.sh include/jemalloc/internal/private_unnamespace.sh include/jemalloc/internal/private_symbols.txt include/jemalloc/internal/public_namespace.sh include/jemalloc/internal/public_unnamespace.sh include/jemalloc/internal/size_classes.sh include/jemalloc/jemalloc_rename.sh include/jemalloc/jemalloc_mangle.sh include/jemalloc/jemalloc.sh test/include/test/jemalloc_test_defs.h.in
--- 39,45 ----
  install_suffix := 
  ABI := elf
  XSLTPROC := false
! AUTOCONF := false
  _RPATH = -Wl,-rpath,$(1)
  RPATH = $(if $(1),$(call _RPATH,$(1)))
  cfghdrs_in := include/jemalloc/jemalloc_defs.h.in include/jemalloc/internal/jemalloc_internal_defs.h.in include/jemalloc/internal/private_namespace.sh include/jemalloc/internal/private_unnamespace.sh include/jemalloc/internal/private_symbols.txt include/jemalloc/internal/public_namespace.sh include/jemalloc/internal/public_unnamespace.sh include/jemalloc/internal/size_classes.sh include/jemalloc/jemalloc_rename.sh include/jemalloc/jemalloc_mangle.sh include/jemalloc/jemalloc.sh test/include/test/jemalloc_test_defs.h.in
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: arena.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: atomic.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: base.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: bitmap.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: chunk_dss.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: chunk_mmap.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: chunk.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: ckh.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: ctl.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: extent.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: hash.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: huge.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: jemalloc.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: mb.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: mutex.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: prof.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: quarantine.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: rtree.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: stats.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: tcache.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: tsd.o
Only in streaming-benchmarks/redis-3.0.5/deps/jemalloc/src: util.o
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/test/test.sh streaming-benchmarks/redis-3.0.5/deps/jemalloc/test/test.sh
*** streaming-benchmarks_git_compact/redis-3.0.5/deps/jemalloc/test/test.sh	2017-06-07 09:31:37.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/deps/jemalloc/test/test.sh	2017-02-22 05:02:59.634116479 +0000
***************
*** 24,30 ****
      echo
    fi
    echo "=== ${t} ==="
!   ${t} /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/ /home/shyang/temp/sandbox-5/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
    result_code=$?
    case ${result_code} in
      ${pass_code})
--- 24,30 ----
      echo
    fi
    echo "=== ${t} ==="
!   ${t} /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/ /home/centos/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/redis-3.0.5/deps/jemalloc/
    result_code=$?
    case ${result_code} in
      ${pass_code})
Only in streaming-benchmarks/redis-3.0.5/deps/linenoise: linenoise.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: fpconv.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lapi.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lauxlib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lbaselib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lcode.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ldblib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ldebug.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ldo.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ldump.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lfunc.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lgc.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/deps/lua/src/liblua.a and streaming-benchmarks/redis-3.0.5/deps/lua/src/liblua.a differ
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: linit.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: liolib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: llex.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lmathlib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lmem.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: loadlib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lobject.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lopcodes.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: loslib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lparser.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lstate.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lstring.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lstrlib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ltable.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ltablib.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: ltm.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/deps/lua/src/lua and streaming-benchmarks/redis-3.0.5/deps/lua/src/lua differ
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lua_bit.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/deps/lua/src/luac and streaming-benchmarks/redis-3.0.5/deps/lua/src/luac differ
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lua_cjson.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lua_cmsgpack.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: luac.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lua.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lua_struct.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lundump.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lvm.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: lzio.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: print.o
Only in streaming-benchmarks/redis-3.0.5/deps/lua/src: strbuf.o
Only in streaming-benchmarks/redis-3.0.5/src: adlist.o
Only in streaming-benchmarks/redis-3.0.5/src: ae.o
Only in streaming-benchmarks/redis-3.0.5/src: anet.o
Only in streaming-benchmarks/redis-3.0.5/src: aof.o
Only in streaming-benchmarks/redis-3.0.5/src: bio.o
Only in streaming-benchmarks/redis-3.0.5/src: bitops.o
Only in streaming-benchmarks/redis-3.0.5/src: blocked.o
Only in streaming-benchmarks/redis-3.0.5/src: cluster.o
Only in streaming-benchmarks/redis-3.0.5/src: config.o
Only in streaming-benchmarks/redis-3.0.5/src: crc16.o
Only in streaming-benchmarks/redis-3.0.5/src: crc64.o
Only in streaming-benchmarks/redis-3.0.5/src: db.o
Only in streaming-benchmarks/redis-3.0.5/src: debug.o
Only in streaming-benchmarks/redis-3.0.5/src: dict.o
Only in streaming-benchmarks/redis-3.0.5/src: endianconv.o
Only in streaming-benchmarks/redis-3.0.5/src: hyperloglog.o
Only in streaming-benchmarks/redis-3.0.5/src: intset.o
Only in streaming-benchmarks/redis-3.0.5/src: latency.o
Only in streaming-benchmarks/redis-3.0.5/src: lzf_c.o
Only in streaming-benchmarks/redis-3.0.5/src: lzf_d.o
Only in streaming-benchmarks/redis-3.0.5/src: memtest.o
Only in streaming-benchmarks/redis-3.0.5/src: multi.o
Only in streaming-benchmarks/redis-3.0.5/src: networking.o
Only in streaming-benchmarks/redis-3.0.5/src: notify.o
Only in streaming-benchmarks/redis-3.0.5/src: object.o
Only in streaming-benchmarks/redis-3.0.5/src: pqsort.o
Only in streaming-benchmarks/redis-3.0.5/src: pubsub.o
Only in streaming-benchmarks/redis-3.0.5/src: rand.o
Only in streaming-benchmarks/redis-3.0.5/src: rdb.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/src/redis-benchmark and streaming-benchmarks/redis-3.0.5/src/redis-benchmark differ
Only in streaming-benchmarks/redis-3.0.5/src: redis-benchmark.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/src/redis-check-aof and streaming-benchmarks/redis-3.0.5/src/redis-check-aof differ
Only in streaming-benchmarks/redis-3.0.5/src: redis-check-aof.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/src/redis-check-dump and streaming-benchmarks/redis-3.0.5/src/redis-check-dump differ
Only in streaming-benchmarks/redis-3.0.5/src: redis-check-dump.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/src/redis-cli and streaming-benchmarks/redis-3.0.5/src/redis-cli differ
Only in streaming-benchmarks/redis-3.0.5/src: redis-cli.o
Only in streaming-benchmarks/redis-3.0.5/src: redis.o
Binary files streaming-benchmarks_git_compact/redis-3.0.5/src/redis-sentinel and streaming-benchmarks/redis-3.0.5/src/redis-sentinel differ
Binary files streaming-benchmarks_git_compact/redis-3.0.5/src/redis-server and streaming-benchmarks/redis-3.0.5/src/redis-server differ
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/redis-3.0.5/src/release.h streaming-benchmarks/redis-3.0.5/src/release.h
*** streaming-benchmarks_git_compact/redis-3.0.5/src/release.h	2017-06-07 09:31:30.000000000 +0000
--- streaming-benchmarks/redis-3.0.5/src/release.h	2017-02-08 09:37:38.619000000 +0000
***************
*** 1,3 ****
! #define REDIS_GIT_SHA1 "b073202b"
  #define REDIS_GIT_DIRTY "0"
! #define REDIS_BUILD_ID "elc-1-1496827890"
--- 1,3 ----
! #define REDIS_GIT_SHA1 "00000000"
  #define REDIS_GIT_DIRTY "0"
! #define REDIS_BUILD_ID "elc-1-1485394030"
Only in streaming-benchmarks/redis-3.0.5/src: release.o
Only in streaming-benchmarks/redis-3.0.5/src: replication.o
Only in streaming-benchmarks/redis-3.0.5/src: rio.o
Only in streaming-benchmarks/redis-3.0.5/src: scripting.o
Only in streaming-benchmarks/redis-3.0.5/src: sds.o
Only in streaming-benchmarks/redis-3.0.5/src: sentinel.o
Only in streaming-benchmarks/redis-3.0.5/src: setproctitle.o
Only in streaming-benchmarks/redis-3.0.5/src: sha1.o
Only in streaming-benchmarks/redis-3.0.5/src: slowlog.o
Only in streaming-benchmarks/redis-3.0.5/src: sort.o
Only in streaming-benchmarks/redis-3.0.5/src: sparkline.o
Only in streaming-benchmarks/redis-3.0.5/src: syncio.o
Only in streaming-benchmarks/redis-3.0.5/src: t_hash.o
Only in streaming-benchmarks/redis-3.0.5/src: t_list.o
Only in streaming-benchmarks/redis-3.0.5/src: t_set.o
Only in streaming-benchmarks/redis-3.0.5/src: t_string.o
Only in streaming-benchmarks/redis-3.0.5/src: t_zset.o
Only in streaming-benchmarks/redis-3.0.5/src: util.o
Only in streaming-benchmarks/redis-3.0.5/src: ziplist.o
Only in streaming-benchmarks/redis-3.0.5/src: zipmap.o
Only in streaming-benchmarks/redis-3.0.5/src: zmalloc.o
Only in streaming-benchmarks: results
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/conf/log4j.properties.template streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/conf/log4j.properties.template
*** streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/conf/log4j.properties.template	2016-06-22 02:14:03.000000000 +0000
--- streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/conf/log4j.properties.template	2017-02-08 16:13:44.305764352 +0000
***************
*** 29,34 ****
--- 29,35 ----
  log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
  log4j.logger.org.apache.parquet=ERROR
  log4j.logger.parquet=ERROR
+ log4j.logger.org.apache.spark.streaming.kafka010.DirectKafkaInputDStream=INFO
  
  # SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
  log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/conf: slaves
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/lib: datanucleus-api-jdo-3.2.6.jar
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/lib: datanucleus-core-3.2.10.jar
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/lib: datanucleus-rdbms-3.2.9.jar
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/lib: spark-1.6.2-yarn-shuffle.jar
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/lib: spark-assembly-1.6.2-hadoop2.6.0.jar
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/lib: spark-examples-1.6.2-hadoop2.6.0.jar
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6: logs
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/python/lib/pyspark.zip and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/python/lib/pyspark.zip differ
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/DESCRIPTION streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/DESCRIPTION
*** streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/DESCRIPTION	2016-06-22 02:14:03.000000000 +0000
--- streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/DESCRIPTION	2017-03-27 05:35:11.667322079 +0000
***************
*** 10,19 ****
  Suggests: testthat
  Description: R frontend for Spark
  License: Apache License (== 2.0)
! Collate: 'schema.R' 'generics.R' 'jobj.R' 'RDD.R' 'pairRDD.R'
!         'column.R' 'group.R' 'DataFrame.R' 'SQLContext.R' 'backend.R'
          'broadcast.R' 'client.R' 'context.R' 'deserialize.R'
          'functions.R' 'mllib.R' 'serialize.R' 'sparkR.R' 'stats.R'
          'types.R' 'utils.R'
  RoxygenNote: 5.0.1
! Built: R 3.1.1; ; 2016-06-22 02:00:03 UTC; unix
--- 10,19 ----
  Suggests: testthat
  Description: R frontend for Spark
  License: Apache License (== 2.0)
! Collate: 'schema.R' 'generics.R' 'jobj.R' 'column.R' 'group.R' 'RDD.R'
!         'pairRDD.R' 'DataFrame.R' 'SQLContext.R' 'backend.R'
          'broadcast.R' 'client.R' 'context.R' 'deserialize.R'
          'functions.R' 'mllib.R' 'serialize.R' 'sparkR.R' 'stats.R'
          'types.R' 'utils.R'
  RoxygenNote: 5.0.1
! Built: R 3.0.2; ; 2017-03-13 15:25:58 UTC; unix
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/aliases.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/aliases.rds differ
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/AnIndex streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/AnIndex
*** streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/AnIndex	2016-06-22 02:14:03.000000000 +0000
--- streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/AnIndex	2017-02-08 16:13:50.362765424 +0000
***************
*** 1,301 ****
- $	select
- $<-	select
- %in%	match
- abs	abs
- acos	acos
- add_months	add_months
- agg	agg
- agg	summarize
- alias	alias
- approxCountDistinct	approxCountDistinct
- arrange	arrange
- array_contains	array_contains
- as.data.frame	as.data.frame
- as.data.frame,DataFrame-method	as.data.frame
- as.DataFrame	createDataFrame
- asc	column
- ascii	ascii
- asin	asin
- atan	atan
- atan2	atan2
- attach	attach
- attach,DataFrame-method	attach
- avg	avg
- base64	base64
- between	between
- between	column
- bin	bin
- bitwiseNOT	bitwiseNOT
- cache	cache
- cacheTable	cacheTable
- cancelJobGroup	cancelJobGroup
- cast	cast
- cast	column
- cbrt	cbrt
- ceil	ceil
- ceiling	ceil
- clearCache	clearCache
- clearJobGroup	clearJobGroup
- col	col
- collect	collect
- colnames	columns
- colnames<-	columns
- coltypes	coltypes
- coltypes<-	coltypes
- column	col
- Column-class	column
- columns	columns
- columns	schema
- concat	concat
- concat_ws	concat_ws
- contains	column
- conv	conv
- corr	corr
- corr	statfunctions
- cos	cos
- cosh	cosh
- count	count
- count	nrow
- count,GroupedData-method	agg
- countDistinct	countDistinct
- cov	statfunctions
- crc32	crc32
- createDataFrame	createDataFrame
- createExternalTable	createExternalTable
- crosstab	statfunctions
- cume_dist	cume_dist
- dataFrame	DataFrame
- DataFrame-class	DataFrame
- datediff	datediff
- date_add	date_add
- date_format	date_format
- date_sub	date_sub
- dayofmonth	dayofmonth
- dayofyear	dayofyear
- decode	decode
- dense_rank	dense_rank
- desc	column
- describe	summary
- dim	dim
- distinct	distinct
- dropna	nafunctions
- dropTempTable	dropTempTable
- dtypes	dtypes
- dtypes	schema
- encode	encode
- endsWith	column
- except	except
- exp	exp
- explain	explain
- explode	explode
- expm1	expm1
- expr	expr
- factorial	factorial
- fillna	nafunctions
- filter	filter
- first	first
- floor	floor
- format_number	format_number
- format_string	format_string
- freqItems	statfunctions
- from_unixtime	from_unixtime
- from_utc_timestamp	from_utc_timestamp
- generateAliasesForIntersectedCols	generateAliasesForIntersectedCols
- getField	column
- getItem	column
- glm	glm
- glm,formula,ANY,DataFrame-method	glm
- greatest	greatest
- groupBy	groupBy
- groupedData	DataFrame
- GroupedData-class	GroupedData
- group_by	groupBy
- hashCode	hashCode
- head	head
- hex	hex
- hour	hour
- hypot	hypot
- ifelse	ifelse
- infer_type	infer_type
- initcap	initcap
- insertInto	insertInto
- instr	instr
- intersect	intersect
- is.nan	is.nan
- isLocal	isLocal
- isNaN	column
- isnan	is.nan
- isNotNull	column
- isNull	column
- join	join
- jsonFile	read.json
- kurtosis	kurtosis
- lag	lag
- last	last
- last_day	last_day
- lead	lead
- least	least
- length	length
- levenshtein	levenshtein
- like	column
- limit	limit
- lit	lit
- loadDF	read.df
- locate	locate
- log	log
- log10	log10
- log1p	log1p
- log2	log2
- lower	lower
- lpad	lpad
- ltrim	ltrim
- max	max
- md5	md5
- mean	mean
- merge	merge
- min	min
- minute	minute
- month	month
- months_between	months_between
- mutate	mutate
- n	count
- na.omit	nafunctions
- names	columns
- names<-	columns
- nanvl	nanvl
- ncol	ncol
- negate	negate
- next_day	next_day
- nrow	nrow
- ntile	ntile
- n_distinct	countDistinct
- orderBy	arrange
- otherwise	column
- otherwise	otherwise
- parquetFile	read.parquet
- percent_rank	percent_rank
- persist	persist
- PipelineModel-class	PipelineModel-class
- pmod	pmod
- predict	predict
- predict,PipelineModel-method	predict
- print.jobj	print.jobj
- print.structField	print.structField
- print.structType	print.structType
- printSchema	printSchema
- printSchema	schema
- quarter	quarter
- rand	rand
- randn	randn
- rank	rank
- rbind	rbind
- read.df	read.df
- read.json	read.json
- read.parquet	read.parquet
- read.text	read.text
- regexp_extract	regexp_extract
- regexp_replace	regexp_replace
- registerTempTable	registerTempTable
- rename	rename
- repartition	repartition
- reverse	reverse
- rint	rint
- rlike	column
- round	round
- row_number	row_number
- rpad	rpad
- rtrim	rtrim
- sample	sample
- sampleBy	statfunctions
- sample_frac	sample
- saveAsParquetFile	write.parquet
- saveAsTable	saveAsTable
- saveDF	write.df
- schema	schema
- sd	sd
- second	second
- select	select
- select,DataFrame,Column-method	select
- select,DataFrame,list-method	select
- selectExpr	select
- selectExpr	selectExpr
- setJobGroup	setJobGroup
- sha1	sha1
- sha2	sha2
- shiftLeft	shiftLeft
- shiftRight	shiftRight
- shiftRightUnsigned	shiftRightUnsigned
- show	show
- show,GroupedData-method	show
- showDF	showDF
- sign	signum
- signum	signum
- sin	sin
- sinh	sinh
- size	size
- skewness	skewness
- sort_array	sort_array
- soundex	soundex
- sparkR.init	sparkR.init
- sparkR.stop	sparkR.stop
- sparkRHive.init	sparkRHive.init
- sparkRSQL.init	sparkRSQL.init
- sql	sql
- sqrt	sqrt
- startsWith	column
- stddev	sd
- stddev_pop	stddev_pop
- stddev_samp	stddev_samp
- str	str
- struct	struct
- structField	structField
- structType	structType
- subset	subset
- substr	substr
- substring_index	substring_index
- sum	sum
- sumDistinct	sumDistinct
- summarize	agg
- summarize	summarize
- summary	summary
- summary,PipelineModel-method	summary
- table	table
- tableNames	tableNames
- tables	tables
- take	take
- tan	tan
- tanh	tanh
- toDegrees	toDegrees
- toRadians	toRadians
- to_date	to_date
- to_utc_timestamp	to_utc_timestamp
- transform	mutate
- translate	translate
- trim	trim
- unbase64	unbase64
- uncacheTable	uncacheTable
- unhex	unhex
- unionAll	rbind
- unique	distinct
- unix_timestamp	unix_timestamp
- unpersist	unpersist-methods
- upper	upper
- var	var
- variance	var
- var_pop	var_pop
- var_samp	var_samp
- weekofyear	weekofyear
- when	column
- when	when
- where	filter
- with	with
- with,DataFrame-method	with
- withColumn	withColumn
- withColumnRenamed	rename
- write.df	write.df
- write.json	write.json
- write.parquet	write.parquet
- write.text	write.text
- year	year
- [	subset
- [[	subset
--- 0 ----
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/paths.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/paths.rds differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/SparkR.rdb and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/SparkR.rdb differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/SparkR.rdx and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/help/SparkR.rdx differ
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/html/00Index.html streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/html/00Index.html
*** streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/html/00Index.html	2016-06-22 02:14:03.000000000 +0000
--- streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/html/00Index.html	2017-03-27 05:35:11.667322079 +0000
***************
*** 18,774 ****
  <h2>Help Pages</h2>
  
  
! <p align="center">
! <a href="#A">A</a>
! <a href="#B">B</a>
! <a href="#C">C</a>
! <a href="#D">D</a>
! <a href="#E">E</a>
! <a href="#F">F</a>
! <a href="#G">G</a>
! <a href="#H">H</a>
! <a href="#I">I</a>
! <a href="#J">J</a>
! <a href="#K">K</a>
! <a href="#L">L</a>
! <a href="#M">M</a>
! <a href="#N">N</a>
! <a href="#O">O</a>
! <a href="#P">P</a>
! <a href="#Q">Q</a>
! <a href="#R">R</a>
! <a href="#S">S</a>
! <a href="#T">T</a>
! <a href="#U">U</a>
! <a href="#V">V</a>
! <a href="#W">W</a>
! <a href="#Y">Y</a>
! <a href="#misc">misc</a>
! </p>
! 
! 
! <h2><a name="A">-- A --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="abs.html">abs</a></td>
! <td>abs</td></tr>
! <tr><td width="25%"><a href="acos.html">acos</a></td>
! <td>acos</td></tr>
! <tr><td width="25%"><a href="add_months.html">add_months</a></td>
! <td>add_months</td></tr>
! <tr><td width="25%"><a href="agg.html">agg</a></td>
! <td>Summarize data across columns</td></tr>
! <tr><td width="25%"><a href="summarize.html">agg</a></td>
! <td>summarize</td></tr>
! <tr><td width="25%"><a href="alias.html">alias</a></td>
! <td>alias</td></tr>
! <tr><td width="25%"><a href="approxCountDistinct.html">approxCountDistinct</a></td>
! <td>approxCountDistinct</td></tr>
! <tr><td width="25%"><a href="arrange.html">arrange</a></td>
! <td>Arrange</td></tr>
! <tr><td width="25%"><a href="array_contains.html">array_contains</a></td>
! <td>array_contains</td></tr>
! <tr><td width="25%"><a href="as.data.frame.html">as.data.frame</a></td>
! <td>Download data from a DataFrame into a data.frame</td></tr>
! <tr><td width="25%"><a href="as.data.frame.html">as.data.frame-method</a></td>
! <td>Download data from a DataFrame into a data.frame</td></tr>
! <tr><td width="25%"><a href="createDataFrame.html">as.DataFrame</a></td>
! <td>Create a DataFrame</td></tr>
! <tr><td width="25%"><a href="column.html">asc</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="ascii.html">ascii</a></td>
! <td>ascii</td></tr>
! <tr><td width="25%"><a href="asin.html">asin</a></td>
! <td>asin</td></tr>
! <tr><td width="25%"><a href="atan.html">atan</a></td>
! <td>atan</td></tr>
! <tr><td width="25%"><a href="atan2.html">atan2</a></td>
! <td>atan2</td></tr>
! <tr><td width="25%"><a href="attach.html">attach</a></td>
! <td>Attach DataFrame to R search path</td></tr>
! <tr><td width="25%"><a href="attach.html">attach-method</a></td>
! <td>Attach DataFrame to R search path</td></tr>
! <tr><td width="25%"><a href="avg.html">avg</a></td>
! <td>avg</td></tr>
! </table>
! 
! <h2><a name="B">-- B --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="base64.html">base64</a></td>
! <td>base64</td></tr>
! <tr><td width="25%"><a href="between.html">between</a></td>
! <td>between</td></tr>
! <tr><td width="25%"><a href="column.html">between</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="bin.html">bin</a></td>
! <td>bin</td></tr>
! <tr><td width="25%"><a href="bitwiseNOT.html">bitwiseNOT</a></td>
! <td>bitwiseNOT</td></tr>
! </table>
! 
! <h2><a name="C">-- C --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="cache.html">cache</a></td>
! <td>Cache</td></tr>
! <tr><td width="25%"><a href="cacheTable.html">cacheTable</a></td>
! <td>Cache Table</td></tr>
! <tr><td width="25%"><a href="cancelJobGroup.html">cancelJobGroup</a></td>
! <td>Cancel active jobs for the specified group</td></tr>
! <tr><td width="25%"><a href="cast.html">cast</a></td>
! <td>Casts the column to a different data type.</td></tr>
! <tr><td width="25%"><a href="column.html">cast</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="cbrt.html">cbrt</a></td>
! <td>cbrt</td></tr>
! <tr><td width="25%"><a href="ceil.html">ceil</a></td>
! <td>ceil</td></tr>
! <tr><td width="25%"><a href="ceil.html">ceiling</a></td>
! <td>ceil</td></tr>
! <tr><td width="25%"><a href="clearCache.html">clearCache</a></td>
! <td>Clear Cache</td></tr>
! <tr><td width="25%"><a href="clearJobGroup.html">clearJobGroup</a></td>
! <td>Clear current job group ID and its description</td></tr>
! <tr><td width="25%"><a href="col.html">col</a></td>
! <td>Though scala functions has "col" function, we don't expose it in SparkR because we don't want to conflict with the "col" function in the R base package and we also have "column" function exported which is an alias of "col".</td></tr>
! <tr><td width="25%"><a href="collect.html">collect</a></td>
! <td>Collects all the elements of a Spark DataFrame and coerces them into an R data.frame.</td></tr>
! <tr><td width="25%"><a href="columns.html">colnames</a></td>
! <td>Column names</td></tr>
! <tr><td width="25%"><a href="columns.html">colnames&lt;-</a></td>
! <td>Column names</td></tr>
! <tr><td width="25%"><a href="coltypes.html">coltypes</a></td>
! <td>coltypes</td></tr>
! <tr><td width="25%"><a href="coltypes.html">coltypes&lt;-</a></td>
! <td>coltypes</td></tr>
! <tr><td width="25%"><a href="col.html">column</a></td>
! <td>Though scala functions has "col" function, we don't expose it in SparkR because we don't want to conflict with the "col" function in the R base package and we also have "column" function exported which is an alias of "col".</td></tr>
! <tr><td width="25%"><a href="column.html">Column-class</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="columns.html">columns</a></td>
! <td>Column names</td></tr>
! <tr><td width="25%"><a href="schema.html">columns</a></td>
! <td>Get schema object</td></tr>
! <tr><td width="25%"><a href="concat.html">concat</a></td>
! <td>concat</td></tr>
! <tr><td width="25%"><a href="concat_ws.html">concat_ws</a></td>
! <td>concat_ws</td></tr>
! <tr><td width="25%"><a href="column.html">contains</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="conv.html">conv</a></td>
! <td>conv</td></tr>
! <tr><td width="25%"><a href="corr.html">corr</a></td>
! <td>corr</td></tr>
! <tr><td width="25%"><a href="statfunctions.html">corr</a></td>
! <td>crosstab</td></tr>
! <tr><td width="25%"><a href="cos.html">cos</a></td>
! <td>cos</td></tr>
! <tr><td width="25%"><a href="cosh.html">cosh</a></td>
! <td>cosh</td></tr>
! <tr><td width="25%"><a href="count.html">count</a></td>
! <td>count</td></tr>
! <tr><td width="25%"><a href="nrow.html">count</a></td>
! <td>nrow</td></tr>
! <tr><td width="25%"><a href="agg.html">count-method</a></td>
! <td>Summarize data across columns</td></tr>
! <tr><td width="25%"><a href="countDistinct.html">countDistinct</a></td>
! <td>Count Distinct</td></tr>
! <tr><td width="25%"><a href="statfunctions.html">cov</a></td>
! <td>crosstab</td></tr>
! <tr><td width="25%"><a href="crc32.html">crc32</a></td>
! <td>crc32</td></tr>
! <tr><td width="25%"><a href="createDataFrame.html">createDataFrame</a></td>
! <td>Create a DataFrame</td></tr>
! <tr><td width="25%"><a href="createExternalTable.html">createExternalTable</a></td>
! <td>Create an external table</td></tr>
! <tr><td width="25%"><a href="statfunctions.html">crosstab</a></td>
! <td>crosstab</td></tr>
! <tr><td width="25%"><a href="cume_dist.html">cume_dist</a></td>
! <td>cume_dist</td></tr>
! </table>
! 
! <h2><a name="D">-- D --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="DataFrame.html">dataFrame</a></td>
! <td>S4 class that represents a DataFrame</td></tr>
! <tr><td width="25%"><a href="DataFrame.html">DataFrame-class</a></td>
! <td>S4 class that represents a DataFrame</td></tr>
! <tr><td width="25%"><a href="datediff.html">datediff</a></td>
! <td>datediff</td></tr>
! <tr><td width="25%"><a href="date_add.html">date_add</a></td>
! <td>date_add</td></tr>
! <tr><td width="25%"><a href="date_format.html">date_format</a></td>
! <td>date_format</td></tr>
! <tr><td width="25%"><a href="date_sub.html">date_sub</a></td>
! <td>date_sub</td></tr>
! <tr><td width="25%"><a href="dayofmonth.html">dayofmonth</a></td>
! <td>dayofmonth</td></tr>
! <tr><td width="25%"><a href="dayofyear.html">dayofyear</a></td>
! <td>dayofyear</td></tr>
! <tr><td width="25%"><a href="decode.html">decode</a></td>
! <td>decode</td></tr>
! <tr><td width="25%"><a href="dense_rank.html">dense_rank</a></td>
! <td>dense_rank</td></tr>
! <tr><td width="25%"><a href="column.html">desc</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="summary.html">describe</a></td>
! <td>summary</td></tr>
! <tr><td width="25%"><a href="dim.html">dim</a></td>
! <td>Returns the dimentions (number of rows and columns) of a DataFrame</td></tr>
! <tr><td width="25%"><a href="distinct.html">distinct</a></td>
! <td>Distinct</td></tr>
! <tr><td width="25%"><a href="nafunctions.html">dropna</a></td>
! <td>dropna</td></tr>
! <tr><td width="25%"><a href="dropTempTable.html">dropTempTable</a></td>
! <td>Drop Temporary Table</td></tr>
! <tr><td width="25%"><a href="dtypes.html">dtypes</a></td>
! <td>DataTypes</td></tr>
! <tr><td width="25%"><a href="schema.html">dtypes</a></td>
! <td>Get schema object</td></tr>
! </table>
! 
! <h2><a name="E">-- E --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="encode.html">encode</a></td>
! <td>encode</td></tr>
! <tr><td width="25%"><a href="column.html">endsWith</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="except.html">except</a></td>
! <td>except</td></tr>
! <tr><td width="25%"><a href="exp.html">exp</a></td>
! <td>exp</td></tr>
! <tr><td width="25%"><a href="explain.html">explain</a></td>
! <td>Explain</td></tr>
! <tr><td width="25%"><a href="explode.html">explode</a></td>
! <td>explode</td></tr>
! <tr><td width="25%"><a href="expm1.html">expm1</a></td>
! <td>expm1</td></tr>
! <tr><td width="25%"><a href="expr.html">expr</a></td>
! <td>expr</td></tr>
! </table>
! 
! <h2><a name="F">-- F --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="factorial.html">factorial</a></td>
! <td>factorial</td></tr>
! <tr><td width="25%"><a href="nafunctions.html">fillna</a></td>
! <td>dropna</td></tr>
! <tr><td width="25%"><a href="filter.html">filter</a></td>
! <td>Filter</td></tr>
! <tr><td width="25%"><a href="first.html">first</a></td>
! <td>Return the first row of a DataFrame</td></tr>
! <tr><td width="25%"><a href="floor.html">floor</a></td>
! <td>floor</td></tr>
! <tr><td width="25%"><a href="format_number.html">format_number</a></td>
! <td>format_number</td></tr>
! <tr><td width="25%"><a href="format_string.html">format_string</a></td>
! <td>format_string</td></tr>
! <tr><td width="25%"><a href="statfunctions.html">freqItems</a></td>
! <td>crosstab</td></tr>
! <tr><td width="25%"><a href="from_unixtime.html">from_unixtime</a></td>
! <td>from_unixtime</td></tr>
! <tr><td width="25%"><a href="from_utc_timestamp.html">from_utc_timestamp</a></td>
! <td>from_utc_timestamp</td></tr>
! </table>
! 
! <h2><a name="G">-- G --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="generateAliasesForIntersectedCols.html">generateAliasesForIntersectedCols</a></td>
! <td>Creates a list of columns by replacing the intersected ones with aliases. The name of the alias column is formed by concatanating the original column name and a suffix.</td></tr>
! <tr><td width="25%"><a href="column.html">getField</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="column.html">getItem</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="glm.html">glm</a></td>
! <td>Fits a generalized linear model</td></tr>
! <tr><td width="25%"><a href="glm.html">glm-method</a></td>
! <td>Fits a generalized linear model</td></tr>
! <tr><td width="25%"><a href="greatest.html">greatest</a></td>
! <td>greatest</td></tr>
! <tr><td width="25%"><a href="groupBy.html">groupBy</a></td>
! <td>GroupBy</td></tr>
! <tr><td width="25%"><a href="DataFrame.html">groupedData</a></td>
! <td>S4 class that represents a DataFrame</td></tr>
! <tr><td width="25%"><a href="GroupedData.html">GroupedData-class</a></td>
! <td>S4 class that represents a GroupedData</td></tr>
! <tr><td width="25%"><a href="groupBy.html">group_by</a></td>
! <td>GroupBy</td></tr>
! </table>
! 
! <h2><a name="H">-- H --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="hashCode.html">hashCode</a></td>
! <td>Compute the hashCode of an object</td></tr>
! <tr><td width="25%"><a href="head.html">head</a></td>
! <td>Head</td></tr>
! <tr><td width="25%"><a href="hex.html">hex</a></td>
! <td>hex</td></tr>
! <tr><td width="25%"><a href="hour.html">hour</a></td>
! <td>hour</td></tr>
! <tr><td width="25%"><a href="hypot.html">hypot</a></td>
! <td>hypot</td></tr>
! </table>
! 
! <h2><a name="I">-- I --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="ifelse.html">ifelse</a></td>
! <td>ifelse</td></tr>
! <tr><td width="25%"><a href="infer_type.html">infer_type</a></td>
! <td>infer the SQL type</td></tr>
! <tr><td width="25%"><a href="initcap.html">initcap</a></td>
! <td>initcap</td></tr>
! <tr><td width="25%"><a href="insertInto.html">insertInto</a></td>
! <td>insertInto</td></tr>
! <tr><td width="25%"><a href="instr.html">instr</a></td>
! <td>instr</td></tr>
! <tr><td width="25%"><a href="intersect.html">intersect</a></td>
! <td>Intersect</td></tr>
! <tr><td width="25%"><a href="is.nan.html">is.nan</a></td>
! <td>is.nan</td></tr>
! <tr><td width="25%"><a href="isLocal.html">isLocal</a></td>
! <td>isLocal</td></tr>
! <tr><td width="25%"><a href="column.html">isNaN</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="is.nan.html">isnan</a></td>
! <td>is.nan</td></tr>
! <tr><td width="25%"><a href="column.html">isNotNull</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="column.html">isNull</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! </table>
! 
! <h2><a name="J">-- J --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="join.html">join</a></td>
! <td>Join</td></tr>
! <tr><td width="25%"><a href="read.json.html">jsonFile</a></td>
! <td>Create a DataFrame from a JSON file.</td></tr>
! </table>
! 
! <h2><a name="K">-- K --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="kurtosis.html">kurtosis</a></td>
! <td>kurtosis</td></tr>
! </table>
! 
! <h2><a name="L">-- L --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="lag.html">lag</a></td>
! <td>lag</td></tr>
! <tr><td width="25%"><a href="last.html">last</a></td>
! <td>last</td></tr>
! <tr><td width="25%"><a href="last_day.html">last_day</a></td>
! <td>last_day</td></tr>
! <tr><td width="25%"><a href="lead.html">lead</a></td>
! <td>lead</td></tr>
! <tr><td width="25%"><a href="least.html">least</a></td>
! <td>least</td></tr>
! <tr><td width="25%"><a href="length.html">length</a></td>
! <td>length</td></tr>
! <tr><td width="25%"><a href="levenshtein.html">levenshtein</a></td>
! <td>levenshtein</td></tr>
! <tr><td width="25%"><a href="column.html">like</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="limit.html">limit</a></td>
! <td>Limit</td></tr>
! <tr><td width="25%"><a href="lit.html">lit</a></td>
! <td>lit</td></tr>
! <tr><td width="25%"><a href="read.df.html">loadDF</a></td>
! <td>Load an DataFrame</td></tr>
! <tr><td width="25%"><a href="locate.html">locate</a></td>
! <td>locate</td></tr>
! <tr><td width="25%"><a href="log.html">log</a></td>
! <td>log</td></tr>
! <tr><td width="25%"><a href="log10.html">log10</a></td>
! <td>log10</td></tr>
! <tr><td width="25%"><a href="log1p.html">log1p</a></td>
! <td>log1p</td></tr>
! <tr><td width="25%"><a href="log2.html">log2</a></td>
! <td>log2</td></tr>
! <tr><td width="25%"><a href="lower.html">lower</a></td>
! <td>lower</td></tr>
! <tr><td width="25%"><a href="lpad.html">lpad</a></td>
! <td>lpad</td></tr>
! <tr><td width="25%"><a href="ltrim.html">ltrim</a></td>
! <td>ltrim</td></tr>
! </table>
! 
! <h2><a name="M">-- M --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="max.html">max</a></td>
! <td>max</td></tr>
! <tr><td width="25%"><a href="md5.html">md5</a></td>
! <td>md5</td></tr>
! <tr><td width="25%"><a href="mean.html">mean</a></td>
! <td>mean</td></tr>
! <tr><td width="25%"><a href="merge.html">merge</a></td>
! <td>Merges two data frames</td></tr>
! <tr><td width="25%"><a href="min.html">min</a></td>
! <td>min</td></tr>
! <tr><td width="25%"><a href="minute.html">minute</a></td>
! <td>minute</td></tr>
! <tr><td width="25%"><a href="month.html">month</a></td>
! <td>month</td></tr>
! <tr><td width="25%"><a href="months_between.html">months_between</a></td>
! <td>months_between</td></tr>
! <tr><td width="25%"><a href="mutate.html">mutate</a></td>
! <td>Mutate</td></tr>
! </table>
! 
! <h2><a name="N">-- N --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="count.html">n</a></td>
! <td>count</td></tr>
! <tr><td width="25%"><a href="nafunctions.html">na.omit</a></td>
! <td>dropna</td></tr>
! <tr><td width="25%"><a href="columns.html">names</a></td>
! <td>Column names</td></tr>
! <tr><td width="25%"><a href="columns.html">names&lt;-</a></td>
! <td>Column names</td></tr>
! <tr><td width="25%"><a href="nanvl.html">nanvl</a></td>
! <td>nanvl</td></tr>
! <tr><td width="25%"><a href="ncol.html">ncol</a></td>
! <td>Returns the number of columns in a DataFrame</td></tr>
! <tr><td width="25%"><a href="negate.html">negate</a></td>
! <td>negate</td></tr>
! <tr><td width="25%"><a href="next_day.html">next_day</a></td>
! <td>next_day</td></tr>
! <tr><td width="25%"><a href="nrow.html">nrow</a></td>
! <td>nrow</td></tr>
! <tr><td width="25%"><a href="ntile.html">ntile</a></td>
! <td>ntile</td></tr>
! <tr><td width="25%"><a href="countDistinct.html">n_distinct</a></td>
! <td>Count Distinct</td></tr>
! </table>
! 
! <h2><a name="O">-- O --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="arrange.html">orderBy</a></td>
! <td>Arrange</td></tr>
! <tr><td width="25%"><a href="column.html">otherwise</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="otherwise.html">otherwise</a></td>
! <td>otherwise</td></tr>
! </table>
! 
! <h2><a name="P">-- P --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="read.parquet.html">parquetFile</a></td>
! <td>Create a DataFrame from a Parquet file.</td></tr>
! <tr><td width="25%"><a href="percent_rank.html">percent_rank</a></td>
! <td>percent_rank</td></tr>
! <tr><td width="25%"><a href="persist.html">persist</a></td>
! <td>Persist</td></tr>
! <tr><td width="25%"><a href="PipelineModel-class.html">PipelineModel-class</a></td>
! <td>S4 class that represents a PipelineModel</td></tr>
! <tr><td width="25%"><a href="pmod.html">pmod</a></td>
! <td>pmod</td></tr>
! <tr><td width="25%"><a href="predict.html">predict</a></td>
! <td>Make predictions from a model</td></tr>
! <tr><td width="25%"><a href="predict.html">predict-method</a></td>
! <td>Make predictions from a model</td></tr>
! <tr><td width="25%"><a href="print.jobj.html">print.jobj</a></td>
! <td>Print a JVM object reference.</td></tr>
! <tr><td width="25%"><a href="print.structField.html">print.structField</a></td>
! <td>Print a Spark StructField.</td></tr>
! <tr><td width="25%"><a href="print.structType.html">print.structType</a></td>
! <td>Print a Spark StructType.</td></tr>
! <tr><td width="25%"><a href="printSchema.html">printSchema</a></td>
! <td>Print Schema of a DataFrame</td></tr>
! <tr><td width="25%"><a href="schema.html">printSchema</a></td>
! <td>Get schema object</td></tr>
! </table>
! 
! <h2><a name="Q">-- Q --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="quarter.html">quarter</a></td>
! <td>quarter</td></tr>
! </table>
! 
! <h2><a name="R">-- R --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="rand.html">rand</a></td>
! <td>rand</td></tr>
! <tr><td width="25%"><a href="randn.html">randn</a></td>
! <td>randn</td></tr>
! <tr><td width="25%"><a href="rank.html">rank</a></td>
! <td>rank</td></tr>
! <tr><td width="25%"><a href="rbind.html">rbind</a></td>
! <td>rbind</td></tr>
! <tr><td width="25%"><a href="read.df.html">read.df</a></td>
! <td>Load an DataFrame</td></tr>
! <tr><td width="25%"><a href="read.json.html">read.json</a></td>
! <td>Create a DataFrame from a JSON file.</td></tr>
! <tr><td width="25%"><a href="read.parquet.html">read.parquet</a></td>
! <td>Create a DataFrame from a Parquet file.</td></tr>
! <tr><td width="25%"><a href="read.text.html">read.text</a></td>
! <td>Create a DataFrame from a text file.</td></tr>
! <tr><td width="25%"><a href="regexp_extract.html">regexp_extract</a></td>
! <td>regexp_extract</td></tr>
! <tr><td width="25%"><a href="regexp_replace.html">regexp_replace</a></td>
! <td>regexp_replace</td></tr>
! <tr><td width="25%"><a href="registerTempTable.html">registerTempTable</a></td>
! <td>Register Temporary Table</td></tr>
! <tr><td width="25%"><a href="rename.html">rename</a></td>
! <td>rename</td></tr>
! <tr><td width="25%"><a href="repartition.html">repartition</a></td>
! <td>Repartition</td></tr>
! <tr><td width="25%"><a href="reverse.html">reverse</a></td>
! <td>reverse</td></tr>
! <tr><td width="25%"><a href="rint.html">rint</a></td>
! <td>rint</td></tr>
! <tr><td width="25%"><a href="column.html">rlike</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="round.html">round</a></td>
! <td>round</td></tr>
! <tr><td width="25%"><a href="row_number.html">row_number</a></td>
! <td>row_number</td></tr>
! <tr><td width="25%"><a href="rpad.html">rpad</a></td>
! <td>rpad</td></tr>
! <tr><td width="25%"><a href="rtrim.html">rtrim</a></td>
! <td>rtrim</td></tr>
! </table>
! 
! <h2><a name="S">-- S --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="sample.html">sample</a></td>
! <td>Sample</td></tr>
! <tr><td width="25%"><a href="statfunctions.html">sampleBy</a></td>
! <td>crosstab</td></tr>
! <tr><td width="25%"><a href="sample.html">sample_frac</a></td>
! <td>Sample</td></tr>
! <tr><td width="25%"><a href="write.parquet.html">saveAsParquetFile</a></td>
! <td>write.parquet</td></tr>
! <tr><td width="25%"><a href="saveAsTable.html">saveAsTable</a></td>
! <td>saveAsTable</td></tr>
! <tr><td width="25%"><a href="write.df.html">saveDF</a></td>
! <td>Save the contents of the DataFrame to a data source</td></tr>
! <tr><td width="25%"><a href="schema.html">schema</a></td>
! <td>Get schema object</td></tr>
! <tr><td width="25%"><a href="sd.html">sd</a></td>
! <td>sd</td></tr>
! <tr><td width="25%"><a href="second.html">second</a></td>
! <td>second</td></tr>
! <tr><td width="25%"><a href="select.html">select</a></td>
! <td>Select</td></tr>
! <tr><td width="25%"><a href="select.html">select-method</a></td>
! <td>Select</td></tr>
! <tr><td width="25%"><a href="select.html">selectExpr</a></td>
! <td>Select</td></tr>
! <tr><td width="25%"><a href="selectExpr.html">selectExpr</a></td>
! <td>SelectExpr</td></tr>
! <tr><td width="25%"><a href="setJobGroup.html">setJobGroup</a></td>
! <td>Assigns a group ID to all the jobs started by this thread until the group ID is set to a different value or cleared.</td></tr>
! <tr><td width="25%"><a href="sha1.html">sha1</a></td>
! <td>sha1</td></tr>
! <tr><td width="25%"><a href="sha2.html">sha2</a></td>
! <td>sha2</td></tr>
! <tr><td width="25%"><a href="shiftLeft.html">shiftLeft</a></td>
! <td>shiftLeft</td></tr>
! <tr><td width="25%"><a href="shiftRight.html">shiftRight</a></td>
! <td>shiftRight</td></tr>
! <tr><td width="25%"><a href="shiftRightUnsigned.html">shiftRightUnsigned</a></td>
! <td>shiftRightUnsigned</td></tr>
! <tr><td width="25%"><a href="show.html">show</a></td>
! <td>show</td></tr>
! <tr><td width="25%"><a href="show.html">show-method</a></td>
! <td>show</td></tr>
! <tr><td width="25%"><a href="showDF.html">showDF</a></td>
! <td>showDF</td></tr>
! <tr><td width="25%"><a href="signum.html">sign</a></td>
! <td>signum</td></tr>
! <tr><td width="25%"><a href="signum.html">signum</a></td>
! <td>signum</td></tr>
! <tr><td width="25%"><a href="sin.html">sin</a></td>
! <td>sin</td></tr>
! <tr><td width="25%"><a href="sinh.html">sinh</a></td>
! <td>sinh</td></tr>
! <tr><td width="25%"><a href="size.html">size</a></td>
! <td>size</td></tr>
! <tr><td width="25%"><a href="skewness.html">skewness</a></td>
! <td>skewness</td></tr>
! <tr><td width="25%"><a href="sort_array.html">sort_array</a></td>
! <td>sort_array</td></tr>
! <tr><td width="25%"><a href="soundex.html">soundex</a></td>
! <td>soundex</td></tr>
! <tr><td width="25%"><a href="sparkR.init.html">sparkR.init</a></td>
! <td>Initialize a new Spark Context.</td></tr>
! <tr><td width="25%"><a href="sparkR.stop.html">sparkR.stop</a></td>
! <td>Stop the Spark context.</td></tr>
! <tr><td width="25%"><a href="sparkRHive.init.html">sparkRHive.init</a></td>
! <td>Initialize a new HiveContext.</td></tr>
! <tr><td width="25%"><a href="sparkRSQL.init.html">sparkRSQL.init</a></td>
! <td>Initialize a new SQLContext.</td></tr>
! <tr><td width="25%"><a href="sql.html">sql</a></td>
! <td>SQL Query</td></tr>
! <tr><td width="25%"><a href="sqrt.html">sqrt</a></td>
! <td>sqrt</td></tr>
! <tr><td width="25%"><a href="column.html">startsWith</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="sd.html">stddev</a></td>
! <td>sd</td></tr>
! <tr><td width="25%"><a href="stddev_pop.html">stddev_pop</a></td>
! <td>stddev_pop</td></tr>
! <tr><td width="25%"><a href="stddev_samp.html">stddev_samp</a></td>
! <td>stddev_samp</td></tr>
! <tr><td width="25%"><a href="str.html">str</a></td>
! <td>Compactly display the structure of a dataset</td></tr>
! <tr><td width="25%"><a href="struct.html">struct</a></td>
! <td>struct</td></tr>
! <tr><td width="25%"><a href="structField.html">structField</a></td>
! <td>structField</td></tr>
! <tr><td width="25%"><a href="structType.html">structType</a></td>
! <td>structType</td></tr>
! <tr><td width="25%"><a href="subset.html">subset</a></td>
! <td>Subset</td></tr>
! <tr><td width="25%"><a href="substr.html">substr</a></td>
! <td>substr</td></tr>
! <tr><td width="25%"><a href="substring_index.html">substring_index</a></td>
! <td>substring_index</td></tr>
! <tr><td width="25%"><a href="sum.html">sum</a></td>
! <td>sum</td></tr>
! <tr><td width="25%"><a href="sumDistinct.html">sumDistinct</a></td>
! <td>sumDistinct</td></tr>
! <tr><td width="25%"><a href="agg.html">summarize</a></td>
! <td>Summarize data across columns</td></tr>
! <tr><td width="25%"><a href="summarize.html">summarize</a></td>
! <td>summarize</td></tr>
! <tr><td width="25%"><a href="summary.html">summary</a></td>
! <td>summary</td></tr>
! <tr><td width="25%"><a href="summary.html">summary-method</a></td>
! <td>summary</td></tr>
! </table>
! 
! <h2><a name="T">-- T --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="table.html">table</a></td>
! <td>Create a DataFrame from a SparkSQL Table</td></tr>
! <tr><td width="25%"><a href="tableNames.html">tableNames</a></td>
! <td>Table Names</td></tr>
! <tr><td width="25%"><a href="tables.html">tables</a></td>
! <td>Tables</td></tr>
! <tr><td width="25%"><a href="take.html">take</a></td>
! <td>Take the first NUM rows of a DataFrame and return a the results as a data.frame</td></tr>
! <tr><td width="25%"><a href="tan.html">tan</a></td>
! <td>tan</td></tr>
! <tr><td width="25%"><a href="tanh.html">tanh</a></td>
! <td>tanh</td></tr>
! <tr><td width="25%"><a href="toDegrees.html">toDegrees</a></td>
! <td>toDegrees</td></tr>
! <tr><td width="25%"><a href="toRadians.html">toRadians</a></td>
! <td>toRadians</td></tr>
! <tr><td width="25%"><a href="to_date.html">to_date</a></td>
! <td>to_date</td></tr>
! <tr><td width="25%"><a href="to_utc_timestamp.html">to_utc_timestamp</a></td>
! <td>to_utc_timestamp</td></tr>
! <tr><td width="25%"><a href="mutate.html">transform</a></td>
! <td>Mutate</td></tr>
! <tr><td width="25%"><a href="translate.html">translate</a></td>
! <td>translate</td></tr>
! <tr><td width="25%"><a href="trim.html">trim</a></td>
! <td>trim</td></tr>
! </table>
! 
! <h2><a name="U">-- U --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="unbase64.html">unbase64</a></td>
! <td>unbase64</td></tr>
! <tr><td width="25%"><a href="uncacheTable.html">uncacheTable</a></td>
! <td>Uncache Table</td></tr>
! <tr><td width="25%"><a href="unhex.html">unhex</a></td>
! <td>unhex</td></tr>
! <tr><td width="25%"><a href="rbind.html">unionAll</a></td>
! <td>rbind</td></tr>
! <tr><td width="25%"><a href="distinct.html">unique</a></td>
! <td>Distinct</td></tr>
! <tr><td width="25%"><a href="unix_timestamp.html">unix_timestamp</a></td>
! <td>unix_timestamp</td></tr>
! <tr><td width="25%"><a href="unpersist-methods.html">unpersist</a></td>
! <td>Unpersist</td></tr>
! <tr><td width="25%"><a href="upper.html">upper</a></td>
! <td>upper</td></tr>
! </table>
! 
! <h2><a name="V">-- V --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="var.html">var</a></td>
! <td>var</td></tr>
! <tr><td width="25%"><a href="var.html">variance</a></td>
! <td>var</td></tr>
! <tr><td width="25%"><a href="var_pop.html">var_pop</a></td>
! <td>var_pop</td></tr>
! <tr><td width="25%"><a href="var_samp.html">var_samp</a></td>
! <td>var_samp</td></tr>
! </table>
! 
! <h2><a name="W">-- W --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="weekofyear.html">weekofyear</a></td>
! <td>weekofyear</td></tr>
! <tr><td width="25%"><a href="column.html">when</a></td>
! <td>S4 class that represents a DataFrame column</td></tr>
! <tr><td width="25%"><a href="when.html">when</a></td>
! <td>when</td></tr>
! <tr><td width="25%"><a href="filter.html">where</a></td>
! <td>Filter</td></tr>
! <tr><td width="25%"><a href="with.html">with</a></td>
! <td>Evaluate a R expression in an environment constructed from a DataFrame</td></tr>
! <tr><td width="25%"><a href="with.html">with-method</a></td>
! <td>Evaluate a R expression in an environment constructed from a DataFrame</td></tr>
! <tr><td width="25%"><a href="withColumn.html">withColumn</a></td>
! <td>WithColumn</td></tr>
! <tr><td width="25%"><a href="rename.html">withColumnRenamed</a></td>
! <td>rename</td></tr>
! <tr><td width="25%"><a href="write.df.html">write.df</a></td>
! <td>Save the contents of the DataFrame to a data source</td></tr>
! <tr><td width="25%"><a href="write.json.html">write.json</a></td>
! <td>write.json</td></tr>
! <tr><td width="25%"><a href="write.parquet.html">write.parquet</a></td>
! <td>write.parquet</td></tr>
! <tr><td width="25%"><a href="write.text.html">write.text</a></td>
! <td>write.text</td></tr>
! </table>
! 
! <h2><a name="Y">-- Y --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="year.html">year</a></td>
! <td>year</td></tr>
! </table>
! 
! <h2><a name="misc">-- misc --</a></h2>
! 
! <table width="100%">
! <tr><td width="25%"><a href="select.html">$</a></td>
! <td>Select</td></tr>
! <tr><td width="25%"><a href="select.html">$&lt;-</a></td>
! <td>Select</td></tr>
! <tr><td width="25%"><a href="match.html">%in%</a></td>
! <td>Match a column with given values.</td></tr>
! <tr><td width="25%"><a href="subset.html">[</a></td>
! <td>Subset</td></tr>
! <tr><td width="25%"><a href="subset.html">[[</a></td>
! <td>Subset</td></tr>
! </table>
  </body></html>
--- 18,22 ----
  <h2>Help Pages</h2>
  
  
! There are no help pages in this package
  </body></html>
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/hsearch.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/hsearch.rds differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/links.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/links.rds differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/nsInfo.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/nsInfo.rds differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/package.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/package.rds differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/Rd.rds and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/Meta/Rd.rds differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/R/SparkR.rdb and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/R/SparkR.rdb differ
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/R/SparkR.rdx and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/R/SparkR.rdx differ
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/SparkR/test_support: sparktestjar_2.10-1.0.jar
Binary files streaming-benchmarks_git_compact/spark-1.6.2-bin-hadoop2.6/R/lib/sparkr.zip and streaming-benchmarks/spark-1.6.2-bin-hadoop2.6/R/lib/sparkr.zip differ
Only in streaming-benchmarks/spark-1.6.2-bin-hadoop2.6: work
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-benchmarks/src/main/scala/AdvertisingSpark.scala streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala
*** streaming-benchmarks_git_compact/spark-benchmarks/src/main/scala/AdvertisingSpark.scala	2017-06-07 09:17:13.000000000 +0000
--- streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala	2017-03-13 14:23:50.348072342 +0000
***************
*** 116,122 ****
          joined.append(",");
        }
  
!       joined.append(_).append(":").append(port);
      })
      return joined.toString();
    }
--- 116,122 ----
          joined.append(",");
        }
  
!       joined.append(_).append(":").append(port).append(",");
      })
      return joined.toString();
    }
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-benchmarks/target/analysis/compile streaming-benchmarks/spark-benchmarks/target/analysis/compile
*** streaming-benchmarks_git_compact/spark-benchmarks/target/analysis/compile	2017-06-07 09:31:29.000000000 +0000
--- streaming-benchmarks/spark-benchmarks/target/analysis/compile	2017-02-08 13:58:26.453294783 +0000
***************
*** 4,10 ****
  0 -> single
  output directories:
  1 items
! output dir -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes
  compile options:
  3 items
  0 -> -unchecked
--- 4,10 ----
  0 -> single
  output directories:
  1 items
! output dir -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes
  compile options:
  3 items
  0 -> -unchecked
***************
*** 31,65 ****
  0 -> false
  products:
  17 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$2.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$3.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$4.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$5.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$6.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$7.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$8.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$9.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$joinHosts$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1$$anonfun$apply$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$queryRedis$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$spark$benchmark$KafkaRedisAdvertisingStream$$writeWindow$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$writeRedisTopLevel$1.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$.class
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream.class
  binary dependencies:
  10 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2/spark-core_2.10-1.6.2.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2/spark-streaming-kafka_2.10-1.6.2.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2/spark-streaming_2.10-1.6.2.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/json/json/20140107/json-20140107.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/org/sedis/sedis_2.10/1.2.2/sedis_2.10-1.2.2.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/.m2/repository/redis/clients/jedis/2.4.2/jedis-2.4.2.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/shyang/temp/sandbox-5/streaming-benchmarks/streaming-benchmark-common/target/streaming-benchmark-common-0.1.0.jar
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /opt/jvm/jdk1.8.0_74/jre/lib/rt.jar
  direct source dependencies:
  0 items
  direct external dependencies:
--- 31,65 ----
  0 -> false
  products:
  17 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$2.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$3.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$4.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$5.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$6.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$7.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$8.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$9.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$joinHosts$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1$$anonfun$apply$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$queryRedis$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$spark$benchmark$KafkaRedisAdvertisingStream$$writeWindow$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$writeRedisTopLevel$1.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$.class
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream.class
  binary dependencies:
  10 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/com/yahoo/stream/streaming-benchmark-common/0.1.0/streaming-benchmark-common-0.1.0.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2/spark-core_2.10-1.6.2.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2/spark-streaming-kafka_2.10-1.6.2.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2/spark-streaming_2.10-1.6.2.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/json/json/20140107/json-20140107.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/org/sedis/sedis_2.10/1.2.2/sedis_2.10-1.2.2.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /home/elclab_streaming/.m2/repository/redis/clients/jedis/2.4.2/jedis-2.4.2.jar
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> /opt/jvm/jdk1.8.0_74/jre/lib/rt.jar
  direct source dependencies:
  0 items
  direct external dependencies:
***************
*** 78,158 ****
  0 items
  class names:
  17 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$1
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$2
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$3
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$4
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$5
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$6
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$7
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$8
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$9
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$joinHosts$1
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$main$1
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$main$1$$anonfun$apply$1
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$queryRedis$1
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$spark$benchmark$KafkaRedisAdvertisingStream$$writeWindow$1
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$writeRedisTopLevel$1
  used names:
  0 items
  product stamps:
  17 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$2.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$3.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$4.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$5.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$6.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$7.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$8.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$9.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$joinHosts$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1$$anonfun$apply$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$queryRedis$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$spark$benchmark$KafkaRedisAdvertisingStream$$writeWindow$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$writeRedisTopLevel$1.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$.class -> lastModified(1496827889000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream.class -> lastModified(1496827889000)
  source stamps:
  1 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> hash(01fc7f65cdfd3b2e5a6eea0219254cb93e41372b)
  binary stamps:
  10 items
! /home/shyang/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar -> lastModified(1459944255000)
! /home/shyang/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2/spark-core_2.10-1.6.2.jar -> lastModified(1489419315000)
! /home/shyang/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2/spark-streaming-kafka_2.10-1.6.2.jar -> lastModified(1485394019000)
! /home/shyang/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2/spark-streaming_2.10-1.6.2.jar -> lastModified(1485790175000)
! /home/shyang/.m2/repository/org/json/json/20140107/json-20140107.jar -> lastModified(1485393976000)
! /home/shyang/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar -> lastModified(1458215763000)
! /home/shyang/.m2/repository/org/sedis/sedis_2.10/1.2.2/sedis_2.10-1.2.2.jar -> lastModified(1459944541000)
! /home/shyang/.m2/repository/redis/clients/jedis/2.4.2/jedis-2.4.2.jar -> lastModified(1459944234000)
! /home/shyang/temp/sandbox-5/streaming-benchmarks/streaming-benchmark-common/target/streaming-benchmark-common-0.1.0.jar -> lastModified(1496827879000)
  /opt/jvm/jdk1.8.0_74/jre/lib/rt.jar -> lastModified(1454124614000)
  class names:
  10 items
! /home/shyang/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar -> kafka.serializer.StringDecoder
! /home/shyang/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2/spark-core_2.10-1.6.2.jar -> org.apache.spark.SparkConf
! /home/shyang/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2/spark-streaming-kafka_2.10-1.6.2.jar -> org.apache.spark.streaming.kafka.KafkaUtils$
! /home/shyang/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2/spark-streaming_2.10-1.6.2.jar -> org.apache.spark.streaming.StreamingContext
! /home/shyang/.m2/repository/org/json/json/20140107/json-20140107.jar -> org.json.JSONObject
! /home/shyang/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar -> scala.Array
! /home/shyang/.m2/repository/org/sedis/sedis_2.10/1.2.2/sedis_2.10-1.2.2.jar -> org.sedis.Pool
! /home/shyang/.m2/repository/redis/clients/jedis/2.4.2/jedis-2.4.2.jar -> redis.clients.jedis.JedisPoolConfig
! /home/shyang/temp/sandbox-5/streaming-benchmarks/streaming-benchmark-common/target/streaming-benchmark-common-0.1.0.jar -> benchmark.common.Utils
  /opt/jvm/jdk1.8.0_74/jre/lib/rt.jar -> java.lang.Object
  internal apis:
  1 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> 
! 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
  external apis:
  0 items
  source infos:
  1 items
! /home/shyang/temp/sandbox-5/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> 
  AAAAAAAAAAA=
  compilations:
  1 items
! 0 -> rO0ABXNyABV4c2J0aS5hcGkuQ29tcGlsYXRpb27t+uDDauigQgIAAkoACXN0YXJ0VGltZVsAB291dHB1dHN0ABpbTHhzYnRpL2FwaS9PdXRwdXRTZXR0aW5nO3hwAAABXIHk9yp1cgAaW0x4c2J0aS5hcGkuT3V0cHV0U2V0dGluZzt/asLzp4elQgIAAHhwAAAAAXNyABd4c2J0aS5hcGkuT3V0cHV0U2V0dGluZ3rZmkd0+x17AgACTAAPb3V0cHV0RGlyZWN0b3J5dAASTGphdmEvbGFuZy9TdHJpbmc7TAAPc291cmNlRGlyZWN0b3J5cQB+AAZ4cHQAUC9ob21lL3NoeWFuZy90ZW1wL3NhbmRib3gtNS9zdHJlYW1pbmctYmVuY2htYXJrcy9zcGFyay1iZW5jaG1hcmtzL3RhcmdldC9jbGFzc2VzdAABLw==
--- 78,158 ----
  0 items
  class names:
  17 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$1
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$2
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$3
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$4
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$5
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$6
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$7
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$8
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$9
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$joinHosts$1
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$main$1
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$main$1$$anonfun$apply$1
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$queryRedis$1
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$spark$benchmark$KafkaRedisAdvertisingStream$$writeWindow$1
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> spark.benchmark.KafkaRedisAdvertisingStream$$anonfun$writeRedisTopLevel$1
  used names:
  0 items
  product stamps:
  17 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$2.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$3.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$4.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$5.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$6.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$7.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$8.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$9.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$joinHosts$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1$$anonfun$apply$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$main$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$queryRedis$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$spark$benchmark$KafkaRedisAdvertisingStream$$writeWindow$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$$anonfun$writeRedisTopLevel$1.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream$.class -> lastModified(1486562306000)
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/target/classes/spark/benchmark/KafkaRedisAdvertisingStream.class -> lastModified(1486562306000)
  source stamps:
  1 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> hash(01fc7f65cdfd3b2e5a6eea0219254cb93e41372b)
  binary stamps:
  10 items
! /home/elclab_streaming/.m2/repository/com/yahoo/stream/streaming-benchmark-common/0.1.0/streaming-benchmark-common-0.1.0.jar -> lastModified(1486561907000)
! /home/elclab_streaming/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar -> lastModified(1486553185000)
! /home/elclab_streaming/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2/spark-core_2.10-1.6.2.jar -> lastModified(1486562284000)
! /home/elclab_streaming/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2/spark-streaming-kafka_2.10-1.6.2.jar -> lastModified(1486558750000)
! /home/elclab_streaming/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2/spark-streaming_2.10-1.6.2.jar -> lastModified(1486558750000)
! /home/elclab_streaming/.m2/repository/org/json/json/20140107/json-20140107.jar -> lastModified(1486558747000)
! /home/elclab_streaming/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar -> lastModified(1486550635000)
! /home/elclab_streaming/.m2/repository/org/sedis/sedis_2.10/1.2.2/sedis_2.10-1.2.2.jar -> lastModified(1486558750000)
! /home/elclab_streaming/.m2/repository/redis/clients/jedis/2.4.2/jedis-2.4.2.jar -> lastModified(1486558748000)
  /opt/jvm/jdk1.8.0_74/jre/lib/rt.jar -> lastModified(1454124614000)
  class names:
  10 items
! /home/elclab_streaming/.m2/repository/com/yahoo/stream/streaming-benchmark-common/0.1.0/streaming-benchmark-common-0.1.0.jar -> benchmark.common.Utils
! /home/elclab_streaming/.m2/repository/org/apache/kafka/kafka_2.10/0.8.2.1/kafka_2.10-0.8.2.1.jar -> kafka.serializer.StringDecoder
! /home/elclab_streaming/.m2/repository/org/apache/spark/spark-core_2.10/1.6.2/spark-core_2.10-1.6.2.jar -> org.apache.spark.SparkConf
! /home/elclab_streaming/.m2/repository/org/apache/spark/spark-streaming-kafka_2.10/1.6.2/spark-streaming-kafka_2.10-1.6.2.jar -> org.apache.spark.streaming.kafka.KafkaUtils$
! /home/elclab_streaming/.m2/repository/org/apache/spark/spark-streaming_2.10/1.6.2/spark-streaming_2.10-1.6.2.jar -> org.apache.spark.streaming.StreamingContext
! /home/elclab_streaming/.m2/repository/org/json/json/20140107/json-20140107.jar -> org.json.JSONObject
! /home/elclab_streaming/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar -> scala.collection.convert.Decorators
! /home/elclab_streaming/.m2/repository/org/sedis/sedis_2.10/1.2.2/sedis_2.10-1.2.2.jar -> org.sedis.Dress$
! /home/elclab_streaming/.m2/repository/redis/clients/jedis/2.4.2/jedis-2.4.2.jar -> redis.clients.jedis.JedisPoolConfig
  /opt/jvm/jdk1.8.0_74/jre/lib/rt.jar -> java.lang.Object
  internal apis:
  1 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> 
! 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
  external apis:
  0 items
  source infos:
  1 items
! /home/elclab_streaming/svn/CloudStreamingScalability/trunk/src/benchmarks/streaming-benchmarks/spark-benchmarks/src/main/scala/AdvertisingSpark.scala -> 
  AAAAAAAAAAA=
  compilations:
  1 items
! 0 -> rO0ABXNyABV4c2J0aS5hcGkuQ29tcGlsYXRpb27t+uDDauigQgIAAkoACXN0YXJ0VGltZVsAB291dHB1dHN0ABpbTHhzYnRpL2FwaS9PdXRwdXRTZXR0aW5nO3hwAAABWh4Ek311cgAaW0x4c2J0aS5hcGkuT3V0cHV0U2V0dGluZzt/asLzp4elQgIAAHhwAAAAAXNyABd4c2J0aS5hcGkuT3V0cHV0U2V0dGluZ3rZmkd0+x17AgACTAAPb3V0cHV0RGlyZWN0b3J5dAASTGphdmEvbGFuZy9TdHJpbmc7TAAPc291cmNlRGlyZWN0b3J5cQB+AAZ4cHQAfi9ob21lL2VsY2xhYl9zdHJlYW1pbmcvc3ZuL0Nsb3VkU3RyZWFtaW5nU2NhbGFiaWxpdHkvdHJ1bmsvc3JjL2JlbmNobWFya3Mvc3RyZWFtaW5nLWJlbmNobWFya3Mvc3BhcmstYmVuY2htYXJrcy90YXJnZXQvY2xhc3Nlc3QAAS8=
Only in streaming-benchmarks_git_compact/spark-benchmarks/target/analysis: compile.relations
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/spark-benchmarks/target/maven-archiver/pom.properties streaming-benchmarks/spark-benchmarks/target/maven-archiver/pom.properties
*** streaming-benchmarks_git_compact/spark-benchmarks/target/maven-archiver/pom.properties	2017-06-07 09:31:29.000000000 +0000
--- streaming-benchmarks/spark-benchmarks/target/maven-archiver/pom.properties	2017-02-08 13:58:27.592294929 +0000
***************
*** 1,5 ****
  #Generated by Maven
! #Wed Jun 07 18:31:29 KST 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=spark-benchmarks
--- 1,5 ----
  #Generated by Maven
! #Wed Feb 08 13:58:27 UTC 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=spark-benchmarks
Only in streaming-benchmarks/spark-benchmarks/target: original-spark-benchmarks-0.1.0.jar
Only in streaming-benchmarks/spark-benchmarks/target: spark-benchmarks-0.1.0.jar
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/storm-benchmarks/src/main/java/storm/benchmark/AdvertisingTopology.java streaming-benchmarks/storm-benchmarks/src/main/java/storm/benchmark/AdvertisingTopology.java
*** streaming-benchmarks_git_compact/storm-benchmarks/src/main/java/storm/benchmark/AdvertisingTopology.java	2017-06-07 09:17:13.000000000 +0000
--- streaming-benchmarks/storm-benchmarks/src/main/java/storm/benchmark/AdvertisingTopology.java	2017-04-19 02:00:09.104257285 +0000
***************
*** 36,52 ****
--- 36,164 ----
  import storm.kafka.StringScheme;
  import storm.kafka.ZkHosts;
  
+ import java.nio.charset.Charset;
+ import java.nio.file.Files;
+ import java.nio.file.Path;
+ import java.nio.file.Paths;
+ import java.nio.file.StandardOpenOption;
+ import java.io.IOException;
+ import java.net.InetAddress;
+ import java.util.ArrayList;
+ import java.util.Arrays;
+ import backtype.storm.generated.GlobalStreamId;
+ 
  /**
   * This is a basic example of a Storm topology.
   */
  public class AdvertisingTopology {
  
+     public static class X11ColorScheme {
+         public static List<String> COLORS = Arrays.asList(
+             // 0-9
+             "#FFB6C1", "#FFC0CB", "#DC143C", "#FFF0F5", "#DB7093", "#FF69B4", "#FF1493", "#C71585",
+             "#DA70D6", "#D8BFD8",
+ 
+             // 10-21
+             "#a6cee3", "#1f78b4", "#b2df8a", "#33a02c", "#fb9a99", "#e31a1c", "#fdbf6f", "#ff7f00",
+             "#cab2d6", "#6a3d9a", "#ffff99", "#b15928",
+ 
+             "#DDA0DD", "#EE82EE", "#FF00FF", "#FF00FF", "#8B008B", "#800080", "#BA55D3", "#9400D3",
+             "#9932CC", "#4B0082", "#8A2BE2", "#9370DB", "#7B68EE", "#6A5ACD", 
+ 
+             "#483D8B", "#F8F8FF", "#E6E6FA", "#0000FF", "#0000CD", "#00008B", "#000080", "#191970", 
+             "#4169E1", "#6495ED", "#B0C4DE", "#778899", "#708090", "#1E90FF", "#F0F8FF", "#4682B4", 
+             "#87CEFA", "#87CEEB", "#00BFFF", "#ADD8E6", "#B0E0E6", "#5F9EA0", "#00CED1", "#F0FFFF", 
+             "#E0FFFF", "#AFEEEE", "#00FFFF", "#00FFFF", "#008B8B", "#008080", "#2F4F4F", "#48D1CC",
+             "#20B2AA", "#40E0D0", "#7FFFD4", "#66CDAA", "#00FA9A", "#F5FFFA", "#00FF7F", "#3CB371",
+             "#2E8B57", "#F0FFF0", "#8FBC8F", "#98FB98", "#90EE90", "#32CD32", "#00FF00", "#228B22",
+             "#008000", "#006400", "#7CFC00", "#7FFF00", "#ADFF2F", "#556B2F", "#9ACD32", "#6B8E23",
+             "#FFFFF0", "#F5F5DC", "#FFFFE0", "#FAFAD2", "#FFFF00", "#808000", "#BDB76B", "#EEE8AA", 
+             "#FFFACD", "#F0E68C", "#FFD700", "#FFF8DC", "#DAA520", "#B8860B", "#FFFAF0", "#FDF5E6", 
+             "#F5DEB3", "#FFA500", "#FFE4B5", "#FFEFD5", "#FFEBCD", "#FFDEAD", "#FAEBD7", "#D2B48C", 
+             "#DEB887", "#FF8C00", "#FFE4C4", "#FAF0E6", "#CD853F", "#FFDAB9", "#F4A460", "#D2691E", 
+             "#8B4513", "#FFF5EE", "#A0522D", "#FFA07A", "#FF7F50", "#FF4500", "#E9967A", "#FF6347", 
+             "#FA8072", "#FFE4E1", "#F08080", "#FFFAFA", "#BC8F8F", "#CD5C5C", "#FF0000", "#A52A2A", 
+             "#B22222", "#8B0000", "#800000", "#FFFFFF", "#F5F5F5", "#DCDCDC", "#D3D3D3", "#C0C0C0", 
+             "#A9A9A9", "#808080", "#696969", "#000000");
+ 
+         public static String colorAt(int index) {
+             return X11ColorScheme.COLORS.get(index);
+         }
+     }
+ 
+     public static class MyKafkaSpout extends KafkaSpout {
+ 
+         public MyKafkaSpout(SpoutConfig spoutConf) {
+             super(spoutConf);
+         }
+ 
+         @Override
+         public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
+             super.open(conf, context, collector);
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + context.getThisTaskId() + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 // from
+                 for (GlobalStreamId source : context.getThisSources().keySet()) {
+                   String srcNode = source.get_componentId()+"_"+source.get_streamId();
+                   lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 }
+                 //current node
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 // to
+                 for (String streamId : context.getThisTargets().keySet()) {
+                   String tarNode = context.getThisComponentId()+"_"+streamId;
+                   lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 }
+                 Path file = Paths.get("storm_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
+         }
+ 
+         @Override
+         public void close() {
+           super.close();
+         }
+     }
+ 
      public static class DeserializeBolt extends BaseRichBolt {
          OutputCollector _collector;
  
          @Override
          public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
              _collector = collector;
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + context.getThisTaskId() + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 // from
+                 for (GlobalStreamId source : context.getThisSources().keySet()) {
+                   String srcNode = source.get_componentId()+"_"+source.get_streamId();
+                   lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 }
+                 //current node
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 // to
+                 for (String streamId : context.getThisTargets().keySet()) {
+                   String tarNode = context.getThisComponentId()+"_"+streamId;
+                   lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 }
+                 Path file = Paths.get("storm_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
          }
  
          @Override
***************
*** 75,80 ****
--- 187,217 ----
          @Override
          public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
              _collector = collector;
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + context.getThisTaskId() + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 // from
+                 for (GlobalStreamId source : context.getThisSources().keySet()) {
+                   String srcNode = source.get_componentId()+"_"+source.get_streamId();
+                   lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 }
+                 //current node
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 // to
+                 for (String streamId : context.getThisTargets().keySet()) {
+                   String tarNode = context.getThisComponentId()+"_"+streamId;
+                   lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 }
+                 Path file = Paths.get("storm_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
          }
  
          @Override
***************
*** 97,102 ****
--- 234,264 ----
          @Override
          public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
              _collector = collector;
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + context.getThisTaskId() + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 // from
+                 for (GlobalStreamId source : context.getThisSources().keySet()) {
+                   String srcNode = source.get_componentId()+"_"+source.get_streamId();
+                   lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 }
+                 //current node
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 // to
+                 for (String streamId : context.getThisTargets().keySet()) {
+                   String tarNode = context.getThisComponentId()+"_"+streamId;
+                   lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 }
+                 Path file = Paths.get("storm_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
          }
  
          @Override
***************
*** 125,130 ****
--- 287,317 ----
              _collector = collector;
              redisAdCampaignCache = new RedisAdCampaignCache(redisServerHost);
              this.redisAdCampaignCache.prepare();
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + context.getThisTaskId() + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 // from
+                 for (GlobalStreamId source : context.getThisSources().keySet()) {
+                   String srcNode = source.get_componentId()+"_"+source.get_streamId();
+                   lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 }
+                 //current node
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 // to
+                 for (String streamId : context.getThisTargets().keySet()) {
+                   String tarNode = context.getThisComponentId()+"_"+streamId;
+                   lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 }
+                 Path file = Paths.get("storm_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
          }
  
          @Override
***************
*** 163,168 ****
--- 350,380 ----
              _collector = collector;
              campaignProcessorCommon = new CampaignProcessorCommon(redisServerHost);
              this.campaignProcessorCommon.prepare();
+             try {
+                 String className = this.getClass().getSimpleName();
+                 String host = InetAddress.getLocalHost().getHostName();
+                 if (host.contains("instance-")) host = host.replaceAll("instance-", "");
+                 else if (host.contains("streaming-group-0-")) host = host.replaceAll("streaming-group-0-", "");
+                 String color = X11ColorScheme.colorAt(Integer.parseInt(host));
+                 String curNode = host + "_" + context.getThisTaskId() + "_" + Integer.toString(this.hashCode());
+                 List<String> lines = new ArrayList<String>();
+                 // from
+                 for (GlobalStreamId source : context.getThisSources().keySet()) {
+                   String srcNode = source.get_componentId()+"_"+source.get_streamId();
+                   lines.add("\""+srcNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+srcNode+"\" -> \""+curNode+"\" [color = \"black\"]");
+                 }
+                 //current node
+                 lines.add("\""+curNode+"\" [label = \""+className+"\", fontname = Helvetica, shape = circle, style = filled, fillcolor = \""+color+"\"];");
+                 // to
+                 for (String streamId : context.getThisTargets().keySet()) {
+                   String tarNode = context.getThisComponentId()+"_"+streamId;
+                   lines.add("\""+tarNode+"\" [label = \"queue\", fontname = Helvetica, shape = box];");
+                   lines.add("\""+curNode+"\" -> \""+tarNode+"\"");
+                 }
+                 Path file = Paths.get("storm_node_"+host+"_"+Integer.toString(this.hashCode())+".txt");
+                 Files.write(file, lines, Charset.forName("UTF-8"), StandardOpenOption.CREATE);
+             } catch (IOException e) { e.printStackTrace(); }
          }
  
          @Override
***************
*** 222,228 ****
  
          SpoutConfig spoutConfig = new SpoutConfig(hosts, kafkaTopic, "/" + kafkaTopic, UUID.randomUUID().toString());
          spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
!         KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);
  
          builder.setSpout("ads", kafkaSpout, kafkaPartitions);
          builder.setBolt("event_deserializer", new DeserializeBolt(), parallel).shuffleGrouping("ads");
--- 434,440 ----
  
          SpoutConfig spoutConfig = new SpoutConfig(hosts, kafkaTopic, "/" + kafkaTopic, UUID.randomUUID().toString());
          spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
!         MyKafkaSpout kafkaSpout = new MyKafkaSpout(spoutConfig);
  
          builder.setSpout("ads", kafkaSpout, kafkaPartitions);
          builder.setBolt("event_deserializer", new DeserializeBolt(), parallel).shuffleGrouping("ads");
Binary files streaming-benchmarks_git_compact/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$CampaignProcessor.class and streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$CampaignProcessor.class differ
Binary files streaming-benchmarks_git_compact/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology.class and streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology.class differ
Binary files streaming-benchmarks_git_compact/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$DeserializeBolt.class and streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$DeserializeBolt.class differ
Binary files streaming-benchmarks_git_compact/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$EventFilterBolt.class and streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$EventFilterBolt.class differ
Binary files streaming-benchmarks_git_compact/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$EventProjectionBolt.class and streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$EventProjectionBolt.class differ
Only in streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark: AdvertisingTopology$MyKafkaSpout.class
Binary files streaming-benchmarks_git_compact/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$RedisJoinBolt.class and streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark/AdvertisingTopology$RedisJoinBolt.class differ
Only in streaming-benchmarks/storm-benchmarks/target/classes/storm/benchmark: AdvertisingTopology$X11ColorScheme.class
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/storm-benchmarks/target/maven-archiver/pom.properties streaming-benchmarks/storm-benchmarks/target/maven-archiver/pom.properties
*** streaming-benchmarks_git_compact/storm-benchmarks/target/maven-archiver/pom.properties	2017-06-07 09:31:20.000000000 +0000
--- streaming-benchmarks/storm-benchmarks/target/maven-archiver/pom.properties	2017-04-19 02:04:23.372805719 +0000
***************
*** 1,5 ****
  #Generated by Maven
! #Wed Jun 07 18:31:20 KST 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=storm-benchmarks
--- 1,5 ----
  #Generated by Maven
! #Wed Apr 19 02:04:23 UTC 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=storm-benchmarks
Only in streaming-benchmarks/storm-benchmarks/target: original-storm-benchmarks-0.1.0.jar
Only in streaming-benchmarks/storm-benchmarks/target: storm-benchmarks-0.1.0.jar
Only in streaming-benchmarks: storm-local
Only in streaming-benchmarks: storm-trend-detector
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/stream-bench.sh streaming-benchmarks/stream-bench.sh
*** streaming-benchmarks_git_compact/stream-bench.sh	2017-06-07 09:17:31.000000000 +0000
--- streaming-benchmarks/stream-bench.sh	2017-05-08 03:45:41.896639235 +0000
***************
*** 6,12 ****
  set -o nounset
  set -o errexit
  
! LEIN=${LEIN:-lein}
  MVN=${MVN:-mvn}
  GIT=${GIT:-git}
  MAKE=${MAKE:-make}
--- 6,22 ----
  set -o nounset
  set -o errexit
  
! SCRIPT_HOME="$(cd "`dirname "$0"`"; pwd)"
! cd "`dirname "$0"`"
! SVN_REPO_DIR=$(svn info | grep "Working Copy Root Path:" | gawk '{print $5}')
! STREAM_BENCH_DIR=${SVN_REPO_DIR}/trunk/src/benchmarks/streaming-benchmarks
! 
! CORES=`lscpu | gawk '/^CPU\(s\):/{print $2}'`
! THREADS_PER_CORE=`lscpu | gawk '/^Thread\(s\) per core:/{print $4}'`
! PHYSICAL_CORES=$((${CORES}/${THREADS_PER_CORE}))
! 
! #LEIN=${LEIN:-lein}
! LEIN="/home/elclab_streaming/bin/lein"
  MVN=${MVN:-mvn}
  GIT=${GIT:-git}
  MAKE=${MAKE:-make}
***************
*** 18,41 ****
  STORM_VERSION=${STORM_VERSION:-"0.9.7"}
  FLINK_VERSION=${FLINK_VERSION:-"1.1.3"}
  SPARK_VERSION=${SPARK_VERSION:-"1.6.2"}
  
  STORM_DIR="apache-storm-$STORM_VERSION"
  REDIS_DIR="redis-$REDIS_VERSION"
  KAFKA_DIR="kafka_$SCALA_BIN_VERSION-$KAFKA_VERSION"
  FLINK_DIR="flink-$FLINK_VERSION"
  SPARK_DIR="spark-$SPARK_VERSION-bin-hadoop2.6"
  
  #Get one of the closet apache mirrors
  APACHE_MIRROR=$(curl 'https://www.apache.org/dyn/closer.cgi' |   grep -o '<strong>[^<]*</strong>' |   sed 's/<[^>]*>//g' |   head -1)
  
  ZK_HOST="localhost"
  ZK_PORT="2181"
! ZK_CONNECTIONS="$ZK_HOST:$ZK_PORT"
! TOPIC=${TOPIC:-"ad-events"}
! PARTITIONS=${PARTITIONS:-1}
! LOAD=${LOAD:-1000}
! CONF_FILE=./conf/localConf.yaml
! TEST_TIME=${TEST_TIME:-240}
  
  pid_match() {
     local VAL=`ps -aef | grep "$1" | grep -v grep | awk '{print $2}'`
--- 28,73 ----
  STORM_VERSION=${STORM_VERSION:-"0.9.7"}
  FLINK_VERSION=${FLINK_VERSION:-"1.1.3"}
  SPARK_VERSION=${SPARK_VERSION:-"1.6.2"}
+ ZK_VERSION=${ZK_VERSION:-"3.4.6"}
+ 
+ MVN="${SVN_REPO_DIR}/trunk/src/spark-${SPARK_VERSION}/build/mvn -T ${PHYSICAL_CORES}C"
  
  STORM_DIR="apache-storm-$STORM_VERSION"
  REDIS_DIR="redis-$REDIS_VERSION"
  KAFKA_DIR="kafka_$SCALA_BIN_VERSION-$KAFKA_VERSION"
  FLINK_DIR="flink-$FLINK_VERSION"
  SPARK_DIR="spark-$SPARK_VERSION-bin-hadoop2.6"
+ ZK_DIR="zookeeper-$ZK_VERSION"
  
  #Get one of the closet apache mirrors
  APACHE_MIRROR=$(curl 'https://www.apache.org/dyn/closer.cgi' |   grep -o '<strong>[^<]*</strong>' |   sed 's/<[^>]*>//g' |   head -1)
  
  ZK_HOST="localhost"
  ZK_PORT="2181"
! ZK_CONNECTIONS="10.140.0.101:2181,10.140.0.102:2181,10.140.0.103:2181"
! 
! KAFKA_BROKERS="10.140.0.105:9092,10.140.0.106:9092,10.140.0.107:9092,10.140.0.108:9092,10.140.0.109:9092"
! 
! BENCHMARK_MODE="YAHOO"
! if [ $# -gt 1 ];
! then
!   if [ "$2" = "TREND_DETECTOR" ];
!   then
!     BENCHMARK_MODE="TREND"
!   fi
! fi
! 
! if [ "$BENCHMARK_MODE" = "TREND" ];
! then
!   TOPIC=${TOPIC:-"wiki-events"}
! else
!   TOPIC=${TOPIC:-"ad-events"}
! fi
! 
! PARTITIONS=${PARTITIONS:-5}
! LOAD=${LOAD:-50000}
! CONF_FILE=./conf/benchmarkConf.yaml
! TEST_TIME=${TEST_TIME:-60}
  
  pid_match() {
     local VAL=`ps -aef | grep "$1" | grep -v grep | awk '{print $2}'`
***************
*** 116,122 ****
    OPERATION=$1
    if [ "SETUP" = "$OPERATION" ];
    then
!     $GIT clean -fd
  
      echo 'kafka.brokers:' > $CONF_FILE
      echo '    - "localhost"' >> $CONF_FILE
--- 148,154 ----
    OPERATION=$1
    if [ "SETUP" = "$OPERATION" ];
    then
!   ##$GIT clean -fd
  
      echo 'kafka.brokers:' > $CONF_FILE
      echo '    - "localhost"' >> $CONF_FILE
***************
*** 130,136 ****
  	echo 'kafka.topic: "'$TOPIC'"' >> $CONF_FILE
  	echo 'kafka.partitions: '$PARTITIONS >> $CONF_FILE
  	echo 'process.hosts: 1' >> $CONF_FILE
! 	echo 'process.cores: 4' >> $CONF_FILE
  	echo 'storm.workers: 1' >> $CONF_FILE
  	echo 'storm.ackers: 2' >> $CONF_FILE
  	echo 'spark.batchtime: 2000' >> $CONF_FILE
--- 162,168 ----
  	echo 'kafka.topic: "'$TOPIC'"' >> $CONF_FILE
  	echo 'kafka.partitions: '$PARTITIONS >> $CONF_FILE
  	echo 'process.hosts: 1' >> $CONF_FILE
! 	echo "process.cores: ${PHYSICAL_CORES}" >> $CONF_FILE
  	echo 'storm.workers: 1' >> $CONF_FILE
  	echo 'storm.ackers: 2' >> $CONF_FILE
  	echo 'spark.batchtime: 2000' >> $CONF_FILE
***************
*** 163,172 ****
  
    elif [ "START_ZK" = "$OPERATION" ];
    then
!     start_if_needed dev_zookeeper ZooKeeper 10 "$STORM_DIR/bin/storm" dev-zookeeper
    elif [ "STOP_ZK" = "$OPERATION" ];
    then
!     stop_if_needed dev_zookeeper ZooKeeper
      rm -rf /tmp/dev-storm-zookeeper
    elif [ "START_REDIS" = "$OPERATION" ];
    then
--- 195,206 ----
  
    elif [ "START_ZK" = "$OPERATION" ];
    then
!     start_if_needed QuorumPeerMain ZooKeeper 10 "$ZK_DIR/bin/zkServer.sh" start "$KAFKA_DIR/config/zookeeper.properties"
!   ##start_if_needed dev_zookeeper ZooKeeper 10 "$STORM_DIR/bin/storm" dev-zookeeper
    elif [ "STOP_ZK" = "$OPERATION" ];
    then
!     stop_if_needed QuorumPeerMain ZooKeeper
!   ##stop_if_needed dev_zookeeper ZooKeeper
      rm -rf /tmp/dev-storm-zookeeper
    elif [ "START_REDIS" = "$OPERATION" ];
    then
***************
*** 178,196 ****
    then
      stop_if_needed redis-server Redis
      rm -f dump.rdb
!   elif [ "START_STORM" = "$OPERATION" ];
    then
!     start_if_needed daemon.name=nimbus "Storm Nimbus" 3 "$STORM_DIR/bin/storm" nimbus
!     start_if_needed daemon.name=supervisor "Storm Supervisor" 3 "$STORM_DIR/bin/storm" supervisor
!     start_if_needed daemon.name=ui "Storm UI" 3 "$STORM_DIR/bin/storm" ui
!     start_if_needed daemon.name=logviewer "Storm LogViewer" 3 "$STORM_DIR/bin/storm" logviewer
      sleep 20
    elif [ "STOP_STORM" = "$OPERATION" ];
    then
!     stop_if_needed daemon.name=nimbus "Storm Nimbus"
!     stop_if_needed daemon.name=supervisor "Storm Supervisor"
!     stop_if_needed daemon.name=ui "Storm UI"
!     stop_if_needed daemon.name=logviewer "Storm LogViewer"
    elif [ "START_KAFKA" = "$OPERATION" ];
    then
      start_if_needed kafka\.Kafka Kafka 10 "$KAFKA_DIR/bin/kafka-server-start.sh" "$KAFKA_DIR/config/server.properties"
--- 212,236 ----
    then
      stop_if_needed redis-server Redis
      rm -f dump.rdb
!   elif [ "START_STORM" = "$OPERATION" ]; # COORDINATION NODE
    then
!     start_if_needed backtype.storm.daemon.nimbus "Storm Nimbus" 3 "$STORM_DIR/bin/storm" nimbus
!   ##start_if_needed backtype.storm.daemon.supervisor "Storm Supervisor" 3 "$STORM_DIR/bin/storm" supervisor
!     start_if_needed backtype.storm.ui.core "Storm UI" 3 "$STORM_DIR/bin/storm" ui
!     start_if_needed backtype.storm.daemon.logviewer "Storm LogViewer" 3 "$STORM_DIR/bin/storm" logviewer
      sleep 20
    elif [ "STOP_STORM" = "$OPERATION" ];
    then
!     stop_if_needed backtype.storm.daemon.nimbus "Storm Nimbus"
!   ##stop_if_needed backtype.storm.daemon.supervisor "Storm Supervisor"
!     stop_if_needed backtype.storm.ui.core "Storm UI"
!     stop_if_needed backtype.storm.daemon.logviewer "Storm LogViewer"
!   elif [ "START_SUPERVISOR" = "$OPERATION" ];
!   then
!     start_if_needed backtype.storm.daemon.supervisor "Storm Supervisor" 3 "$STORM_DIR/bin/storm" supervisor
!   elif [ "STOP_SUPERVISOR" = "$OPERATION" ];
!   then
!     stop_if_needed backtype.storm.daemon.supervisor "Storm Supervisor"
    elif [ "START_KAFKA" = "$OPERATION" ];
    then
      start_if_needed kafka\.Kafka Kafka 10 "$KAFKA_DIR/bin/kafka-server-start.sh" "$KAFKA_DIR/config/server.properties"
***************
*** 201,241 ****
      rm -rf /tmp/kafka-logs/
    elif [ "START_FLINK" = "$OPERATION" ];
    then
!     start_if_needed org.apache.flink.runtime.jobmanager.JobManager Flink 1 $FLINK_DIR/bin/start-local.sh
    elif [ "STOP_FLINK" = "$OPERATION" ];
    then
!     $FLINK_DIR/bin/stop-local.sh
    elif [ "START_SPARK" = "$OPERATION" ];
    then
!     start_if_needed org.apache.spark.deploy.master.Master SparkMaster 5 $SPARK_DIR/sbin/start-master.sh -h localhost -p 7077
!     start_if_needed org.apache.spark.deploy.worker.Worker SparkSlave 5 $SPARK_DIR/sbin/start-slave.sh spark://localhost:7077
    elif [ "STOP_SPARK" = "$OPERATION" ];
    then
      stop_if_needed org.apache.spark.deploy.master.Master SparkMaster
!     stop_if_needed org.apache.spark.deploy.worker.Worker SparkSlave
      sleep 3
    elif [ "START_LOAD" = "$OPERATION" ];
    then
      cd data
      start_if_needed leiningen.core.main "Load Generation" 1 $LEIN run -r -t $LOAD --configPath ../$CONF_FILE
      cd ..
    elif [ "STOP_LOAD" = "$OPERATION" ];
    then
      stop_if_needed leiningen.core.main "Load Generation"
      cd data
      $LEIN run -g --configPath ../$CONF_FILE || true
      cd ..
    elif [ "START_STORM_TOPOLOGY" = "$OPERATION" ];
    then
      "$STORM_DIR/bin/storm" jar ./storm-benchmarks/target/storm-benchmarks-0.1.0.jar storm.benchmark.AdvertisingTopology test-topo -conf $CONF_FILE
      sleep 15
    elif [ "STOP_STORM_TOPOLOGY" = "$OPERATION" ];
    then
      "$STORM_DIR/bin/storm" kill -w 0 test-topo || true
      sleep 10
    elif [ "START_SPARK_PROCESSING" = "$OPERATION" ];
    then
!     "$SPARK_DIR/bin/spark-submit" --master spark://localhost:7077 --class spark.benchmark.KafkaRedisAdvertisingStream ./spark-benchmarks/target/spark-benchmarks-0.1.0.jar "$CONF_FILE" &
      sleep 5
    elif [ "STOP_SPARK_PROCESSING" = "$OPERATION" ];
    then
--- 241,316 ----
      rm -rf /tmp/kafka-logs/
    elif [ "START_FLINK" = "$OPERATION" ];
    then
!   ##start_if_needed org.apache.flink.runtime.jobmanager.JobManager Flink 1 $FLINK_DIR/bin/start-local.sh
!     start_if_needed org.apache.flink.runtime.jobmanager.JobManager Flink 1 "$FLINK_DIR/bin/jobmanager.sh" start cluster
    elif [ "STOP_FLINK" = "$OPERATION" ];
    then
!   ##$FLINK_DIR/bin/stop-local.sh
!   "$FLINK_DIR/bin/jobmanager.sh" stop
!   elif [ "START_FLINK_TASKMANAGER" = "$OPERATION" ];
!   then
!     start_if_needed org.apache.flink.runtime.taskmanager.TaskManager "Flink TaskManager" 3 "$FLINK_DIR/bin/taskmanager.sh" start
!   elif [ "STOP_FLINK_TASKMANAGER" = "$OPERATION" ];
!   then
!     "$FLINK_DIR/bin/taskmanager.sh" stop
    elif [ "START_SPARK" = "$OPERATION" ];
    then
!     start_if_needed org.apache.spark.deploy.master.Master SparkMaster 5 $SPARK_DIR/sbin/start-master.sh -h 10.140.0.110 -p 7077
!   ##start_if_needed org.apache.spark.deploy.worker.Worker SparkSlave 5 $SPARK_DIR/sbin/start-slave.sh spark://10.140.0.110:7077
    elif [ "STOP_SPARK" = "$OPERATION" ];
    then
      stop_if_needed org.apache.spark.deploy.master.Master SparkMaster
!   ##stop_if_needed org.apache.spark.deploy.worker.Worker SparkSlave
      sleep 3
+   elif [ "START_SPARK_SLAVE" = "$OPERATION" ];
+   then
+     start_if_needed org.apache.spark.deploy.worker.Worker SparkSlave 5 $SPARK_DIR/sbin/start-slave.sh spark://10.140.0.110:7077
+   elif [ "STOP_SPARK_SLAVE" = "$OPERATION" ];
+   then
+     stop_if_needed org.apache.spark.deploy.worker.Worker SparkSlave
    elif [ "START_LOAD" = "$OPERATION" ];
    then
+     if [ "$BENCHMARK_MODE" = "TREND" ];
+     then
+     ##cat /home/elclab_streaming/repos/jurassic-storm/WikiPageData/WikiPageData-*.txt | $KAFKA_DIR/bin/kafka-console-producer.sh --zookeeper "$ZK_CONNECTIONS" --broker-list "$KAFKA_BROKERS" --topic $TOPIC 2>/dev/null
+       cat /home/elclab_streaming/repos/jurassic-storm/WikiPageData/WikiPageData-*.txt | $KAFKA_DIR/bin/kafka-console-producer.sh --broker-list "$KAFKA_BROKERS" --topic $TOPIC 2>/dev/null
+     else
        cd data
        start_if_needed leiningen.core.main "Load Generation" 1 $LEIN run -r -t $LOAD --configPath ../$CONF_FILE
        cd ..
+     fi
    elif [ "STOP_LOAD" = "$OPERATION" ];
    then
+     if [ "$BENCHMARK_MODE" = "TREND" ];
+     then
+       stop_if_needed kafka\.Kafka Kafka
+     else
        stop_if_needed leiningen.core.main "Load Generation"
        cd data
        $LEIN run -g --configPath ../$CONF_FILE || true
        cd ..
+     fi
    elif [ "START_STORM_TOPOLOGY" = "$OPERATION" ];
    then
+     if [ "$BENCHMARK_MODE" = "TREND" ];
+     then
+       "$STORM_DIR/bin/storm" jar ./storm-trend-detector/target/storm-trend-detector-0.1.0.jar jurassic.App td-topo -conf $CONF_FILE -layer 3
+     else
        "$STORM_DIR/bin/storm" jar ./storm-benchmarks/target/storm-benchmarks-0.1.0.jar storm.benchmark.AdvertisingTopology test-topo -conf $CONF_FILE
+     fi
      sleep 15
    elif [ "STOP_STORM_TOPOLOGY" = "$OPERATION" ];
    then
+     if [ "$BENCHMARK_MODE" = "TREND" ];
+     then
+       "$STORM_DIR/bin/storm" kill -w 0 td-topo || true
+     else
        "$STORM_DIR/bin/storm" kill -w 0 test-topo || true
+     fi
      sleep 10
    elif [ "START_SPARK_PROCESSING" = "$OPERATION" ];
    then
!     "$SPARK_DIR/bin/spark-submit" --master spark://10.140.0.110:7077 --class spark.benchmark.KafkaRedisAdvertisingStream ./spark-benchmarks/target/spark-benchmarks-0.1.0.jar "$CONF_FILE" &
      sleep 5
    elif [ "STOP_SPARK_PROCESSING" = "$OPERATION" ];
    then
***************
*** 358,364 ****
--- 433,445 ----
  else
    while [ $# -gt 0 ];
    do
+     if [[ "$1" = "TREND_DETECTOR" ]]
+     then
+       echo "$1: Running storm-trend-detector"
+     else
        run "$1"
+     ##shift
+     fi
      shift
    done
  fi
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common/advertising: CampaignProcessorCommon$1.class
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common/advertising: CampaignProcessorCommon.class
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common/advertising: CampaignWindowPair.class
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common/advertising: LRUHashMap.class
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common/advertising: RedisAdCampaignCache.class
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common/advertising: Window.class
Only in streaming-benchmarks/streaming-benchmark-common/target/classes/benchmark/common: Utils.class
diff -crbB '--exclude=.svn' '--exclude=command-cloud.sh' '--exclude=create-cloud.sh' '--exclude=end-cloud.sh' '--exclude=flink-bench-2.sh' '--exclude=flink-bench.sh' '--exclude=list-cloud.sh' '--exclude=run-cloud.sh' '--exclude=scp-cloud.sh' '--exclude=spark-bench.sh' '--exclude=start-cloud.sh' '--exclude=stop-cloud.sh' '--exclude=storm-bench-2.sh' '--exclude=storm-bench.sh' '--exclude=streaming-group-0-command-list' '--exclude=streaming-group-0-command-list-2' '--exclude=streaming-group-0-list' streaming-benchmarks_git_compact/streaming-benchmark-common/target/maven-archiver/pom.properties streaming-benchmarks/streaming-benchmark-common/target/maven-archiver/pom.properties
*** streaming-benchmarks_git_compact/streaming-benchmark-common/target/maven-archiver/pom.properties	2017-06-07 09:31:19.000000000 +0000
--- streaming-benchmarks/streaming-benchmark-common/target/maven-archiver/pom.properties	2017-02-08 13:51:47.564241449 +0000
***************
*** 1,5 ****
  #Generated by Maven
! #Wed Jun 07 18:31:19 KST 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=streaming-benchmark-common
--- 1,5 ----
  #Generated by Maven
! #Wed Feb 08 13:51:47 UTC 2017
  version=0.1.0
  groupId=com.yahoo.stream
  artifactId=streaming-benchmark-common
Only in streaming-benchmarks/streaming-benchmark-common/target: streaming-benchmark-common-0.1.0.jar
Only in streaming-benchmarks: zookeeper-3.4.6
Only in streaming-benchmarks: zookeeper-3.4.6.tgz
